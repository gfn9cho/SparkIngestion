19/09/26 23:09:06 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
19/09/26 23:09:07 INFO RMProxy: Connecting to ResourceManager at ip-10-84-38-68.corp.stateauto.com/10.84.38.68:8032
19/09/26 23:09:07 INFO Client: Requesting a new application from cluster with 6 NodeManagers
19/09/26 23:09:07 INFO Client: Verifying our application has not requested more than the maximum memory capability of the cluster (122880 MB per container)
19/09/26 23:09:07 INFO Client: Will allocate AM container, with 16896 MB memory including 1536 MB overhead
19/09/26 23:09:07 INFO Client: Setting up container launch context for our AM
19/09/26 23:09:07 INFO Client: Setting up the launch environment for our AM container
19/09/26 23:09:07 INFO Client: Preparing resources for our AM container
19/09/26 23:09:07 WARN Client: Neither spark.yarn.jars nor spark.yarn.archive is set, falling back to uploading libraries under SPARK_HOME.
19/09/26 23:09:10 INFO Client: Uploading resource file:/mnt/tmp/spark-590f36ac-0a5b-42bf-893e-a7d7d7301880/__spark_libs__5798158479818962472.zip -> hdfs://ip-10-84-38-68.corp.stateauto.com:8020/user/hadoop/.sparkStaging/application_1567696628598_10769/__spark_libs__5798158479818962472.zip
19/09/26 23:09:11 INFO Client: Uploading resource file:/home/hadoop/processed/jars/edf_dataingestion_v6_v7-assembly-2.0.0.jar -> hdfs://ip-10-84-38-68.corp.stateauto.com:8020/user/hadoop/.sparkStaging/application_1567696628598_10769/edf_dataingestion_v6_v7-assembly-2.0.0.jar
19/09/26 23:09:11 INFO Client: Uploading resource file:/home/hadoop/processed/v6pifdaily/spec_files/v6pif_daily.properties#diProperties.properties -> hdfs://ip-10-84-38-68.corp.stateauto.com:8020/user/hadoop/.sparkStaging/application_1567696628598_10769/v6pif_daily.properties
19/09/26 23:09:11 INFO Client: Uploading resource file:/home/hadoop/processed/v6pifdaily/spec_files/v6pif_lookup_info_daily.csv#v6pif_lookup_info_daily.csv -> hdfs://ip-10-84-38-68.corp.stateauto.com:8020/user/hadoop/.sparkStaging/application_1567696628598_10769/v6pif_lookup_info_daily.csv
19/09/26 23:09:11 INFO Client: Uploading resource file:/home/hadoop/processed/v6pifdaily/spec_files/v6pif_pii_spec_daily.csv#v6pif_pii_spec_daily.csv -> hdfs://ip-10-84-38-68.corp.stateauto.com:8020/user/hadoop/.sparkStaging/application_1567696628598_10769/v6pif_pii_spec_daily.csv
19/09/26 23:09:11 INFO Client: Uploading resource file:/home/hadoop/processed/v6pifdaily/spec_files/v6pif_tables_spec_daily.csv#v6pif_tables_spec_daily.csv -> hdfs://ip-10-84-38-68.corp.stateauto.com:8020/user/hadoop/.sparkStaging/application_1567696628598_10769/v6pif_tables_spec_daily.csv
19/09/26 23:09:11 INFO Client: Deleted staging directory hdfs://ip-10-84-38-68.corp.stateauto.com:8020/user/hadoop/.sparkStaging/application_1567696628598_10769
Exception in thread "main" java.io.FileNotFoundException: File file:/home/hadoop/processed/v6pifdaily/spec_files/v6pif_tables_spec_daily.csv#v6pif_tables_spec_daily.csv does not exist
	at org.apache.hadoop.fs.RawLocalFileSystem.deprecatedGetFileStatus(RawLocalFileSystem.java:640)
	at org.apache.hadoop.fs.RawLocalFileSystem.getFileLinkStatusInternal(RawLocalFileSystem.java:866)
	at org.apache.hadoop.fs.RawLocalFileSystem.getFileStatus(RawLocalFileSystem.java:630)
	at org.apache.hadoop.fs.FilterFileSystem.getFileStatus(FilterFileSystem.java:452)
	at org.apache.hadoop.fs.FileUtil.copy(FileUtil.java:340)
	at org.apache.hadoop.fs.FileUtil.copy(FileUtil.java:292)
	at org.apache.spark.deploy.yarn.Client.copyFileToRemote(Client.scala:384)
	at org.apache.spark.deploy.yarn.Client.org$apache$spark$deploy$yarn$Client$$distribute$1(Client.scala:476)
	at org.apache.spark.deploy.yarn.Client$$anonfun$prepareLocalResources$10$$anonfun$apply$6.apply(Client.scala:598)
	at org.apache.spark.deploy.yarn.Client$$anonfun$prepareLocalResources$10$$anonfun$apply$6.apply(Client.scala:597)
	at scala.collection.mutable.ResizableArray$class.foreach(ResizableArray.scala:59)
	at scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:48)
	at org.apache.spark.deploy.yarn.Client$$anonfun$prepareLocalResources$10.apply(Client.scala:597)
	at org.apache.spark.deploy.yarn.Client$$anonfun$prepareLocalResources$10.apply(Client.scala:596)
	at scala.collection.immutable.List.foreach(List.scala:392)
	at org.apache.spark.deploy.yarn.Client.prepareLocalResources(Client.scala:596)
	at org.apache.spark.deploy.yarn.Client.createContainerLaunchContext(Client.scala:864)
	at org.apache.spark.deploy.yarn.Client.submitApplication(Client.scala:178)
	at org.apache.spark.deploy.yarn.Client.run(Client.scala:1134)
	at org.apache.spark.deploy.yarn.YarnClusterApplication.start(Client.scala:1526)
	at org.apache.spark.deploy.SparkSubmit.org$apache$spark$deploy$SparkSubmit$$runMain(SparkSubmit.scala:849)
	at org.apache.spark.deploy.SparkSubmit.doRunMain$1(SparkSubmit.scala:167)
	at org.apache.spark.deploy.SparkSubmit.submit(SparkSubmit.scala:195)
	at org.apache.spark.deploy.SparkSubmit.doSubmit(SparkSubmit.scala:86)
	at org.apache.spark.deploy.SparkSubmit$$anon$2.doSubmit(SparkSubmit.scala:924)
	at org.apache.spark.deploy.SparkSubmit$.main(SparkSubmit.scala:933)
	at org.apache.spark.deploy.SparkSubmit.main(SparkSubmit.scala)
19/09/26 23:09:11 INFO ShutdownHookManager: Shutdown hook called
19/09/26 23:09:11 INFO ShutdownHookManager: Deleting directory /mnt/tmp/spark-590f36ac-0a5b-42bf-893e-a7d7d7301880
19/09/26 23:09:11 INFO ShutdownHookManager: Deleting directory /mnt/tmp/spark-f92894aa-c003-42d2-8c32-551bfefef979
