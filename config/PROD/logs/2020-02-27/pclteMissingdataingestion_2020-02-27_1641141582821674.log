20/02/27 16:41:16 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
20/02/27 16:41:17 INFO RMProxy: Connecting to ResourceManager at ip-10-84-38-68.corp.stateauto.com/10.84.38.68:8032
20/02/27 16:41:17 INFO Client: Requesting a new application from cluster with 17 NodeManagers
20/02/27 16:41:17 INFO Client: Verifying our application has not requested more than the maximum memory capability of the cluster (122880 MB per container)
20/02/27 16:41:17 INFO Client: Will allocate AM container, with 22528 MB memory including 2048 MB overhead
20/02/27 16:41:17 INFO Client: Setting up container launch context for our AM
20/02/27 16:41:17 INFO Client: Setting up the launch environment for our AM container
20/02/27 16:41:17 INFO Client: Preparing resources for our AM container
20/02/27 16:41:17 WARN Client: Neither spark.yarn.jars nor spark.yarn.archive is set, falling back to uploading libraries under SPARK_HOME.
20/02/27 16:41:20 INFO Client: Uploading resource file:/mnt/tmp/spark-3229c4ba-a33f-4d38-8c2b-49fb53f47805/__spark_libs__9039332524857584433.zip -> hdfs://ip-10-84-38-68.corp.stateauto.com:8020/user/hadoop/.sparkStaging/application_1578014764864_32354/__spark_libs__9039332524857584433.zip
20/02/27 16:41:21 INFO Client: Uploading resource file:/home/hadoop/processed/pclte/missing_data_utils/jars/edf_missing_dataingestion-1.0.0.jar -> hdfs://ip-10-84-38-68.corp.stateauto.com:8020/user/hadoop/.sparkStaging/application_1578014764864_32354/edf_missing_dataingestion-1.0.0.jar
20/02/27 16:41:21 INFO Client: Uploading resource file:/home/hadoop/processed/jars/sqljdbc42.jar -> hdfs://ip-10-84-38-68.corp.stateauto.com:8020/user/hadoop/.sparkStaging/application_1578014764864_32354/sqljdbc42.jar
20/02/27 16:41:21 INFO Client: Uploading resource file:/home/hadoop/processed/pclte/missing_data_utils/spec_files/fairScheduler.xml#fairScheduler.xml -> hdfs://ip-10-84-38-68.corp.stateauto.com:8020/user/hadoop/.sparkStaging/application_1578014764864_32354/fairScheduler.xml
20/02/27 16:41:21 INFO Client: Uploading resource file:/home/hadoop/processed/pclte/missing_data_utils/spec_files/pclte_missing_stg.properties#diProperties.properties -> hdfs://ip-10-84-38-68.corp.stateauto.com:8020/user/hadoop/.sparkStaging/application_1578014764864_32354/pclte_missing_stg.properties
20/02/27 16:41:21 INFO Client: Uploading resource file:/home/hadoop/processed/pclte/spec_files/pclte_lookup_info.csv#pclte_lookup_info.csv -> hdfs://ip-10-84-38-68.corp.stateauto.com:8020/user/hadoop/.sparkStaging/application_1578014764864_32354/pclte_lookup_info.csv
20/02/27 16:41:21 INFO Client: Uploading resource file:/home/hadoop/processed/pclte/spec_files/pclte_pii_spec.csv#pclte_pii_spec.csv -> hdfs://ip-10-84-38-68.corp.stateauto.com:8020/user/hadoop/.sparkStaging/application_1578014764864_32354/pclte_pii_spec.csv
20/02/27 16:41:21 INFO Client: Uploading resource file:/home/hadoop/processed/pclte/spec_files/pclte_table_spec_stg.csv#pclte_table_spec_stg.csv -> hdfs://ip-10-84-38-68.corp.stateauto.com:8020/user/hadoop/.sparkStaging/application_1578014764864_32354/pclte_table_spec_stg.csv
20/02/27 16:41:21 INFO Client: Uploading resource file:/home/hadoop/processed/pclte/missing_data_utils/spec_files/pclte_missing_table_spec.csv#pclte_missing_table_spec.csv -> hdfs://ip-10-84-38-68.corp.stateauto.com:8020/user/hadoop/.sparkStaging/application_1578014764864_32354/pclte_missing_table_spec.csv
20/02/27 16:41:21 INFO Client: Uploading resource file:/etc/spark/conf/hive-site.xml -> hdfs://ip-10-84-38-68.corp.stateauto.com:8020/user/hadoop/.sparkStaging/application_1578014764864_32354/hive-site.xml
20/02/27 16:41:22 INFO Client: Uploading resource file:/mnt/tmp/spark-3229c4ba-a33f-4d38-8c2b-49fb53f47805/__spark_conf__8021382778212675492.zip -> hdfs://ip-10-84-38-68.corp.stateauto.com:8020/user/hadoop/.sparkStaging/application_1578014764864_32354/__spark_conf__.zip
20/02/27 16:41:22 INFO SecurityManager: Changing view acls to: hadoop
20/02/27 16:41:22 INFO SecurityManager: Changing modify acls to: hadoop
20/02/27 16:41:22 INFO SecurityManager: Changing view acls groups to: 
20/02/27 16:41:22 INFO SecurityManager: Changing modify acls groups to: 
20/02/27 16:41:22 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(hadoop); groups with view permissions: Set(); users  with modify permissions: Set(hadoop); groups with modify permissions: Set()
20/02/27 16:41:23 INFO Client: Submitting application application_1578014764864_32354 to ResourceManager
20/02/27 16:41:23 INFO YarnClientImpl: Submitted application application_1578014764864_32354
20/02/27 16:41:24 INFO Client: Application report for application_1578014764864_32354 (state: ACCEPTED)
20/02/27 16:41:24 INFO Client: 
	 client token: N/A
	 diagnostics: AM container is launched, waiting for AM container to Register with RM
	 ApplicationMaster host: N/A
	 ApplicationMaster RPC port: -1
	 queue: default
	 start time: 1582821683950
	 final status: UNDEFINED
	 tracking URL: http://ip-10-84-38-68.corp.stateauto.com:20888/proxy/application_1578014764864_32354/
	 user: hadoop
20/02/27 16:41:25 INFO Client: Application report for application_1578014764864_32354 (state: ACCEPTED)
20/02/27 16:41:26 INFO Client: Application report for application_1578014764864_32354 (state: ACCEPTED)
20/02/27 16:41:27 INFO Client: Application report for application_1578014764864_32354 (state: ACCEPTED)
20/02/27 16:41:28 INFO Client: Application report for application_1578014764864_32354 (state: ACCEPTED)
20/02/27 16:41:29 INFO Client: Application report for application_1578014764864_32354 (state: ACCEPTED)
20/02/27 16:41:30 INFO Client: Application report for application_1578014764864_32354 (state: RUNNING)
20/02/27 16:41:30 INFO Client: 
	 client token: N/A
	 diagnostics: N/A
	 ApplicationMaster host: ip-10-84-41-179.corp.stateauto.com
	 ApplicationMaster RPC port: 46199
	 queue: default
	 start time: 1582821683950
	 final status: UNDEFINED
	 tracking URL: http://ip-10-84-38-68.corp.stateauto.com:20888/proxy/application_1578014764864_32354/
	 user: hadoop
20/02/27 16:41:31 INFO Client: Application report for application_1578014764864_32354 (state: RUNNING)
20/02/27 16:41:32 INFO Client: Application report for application_1578014764864_32354 (state: RUNNING)
20/02/27 16:41:33 INFO Client: Application report for application_1578014764864_32354 (state: RUNNING)
20/02/27 16:41:34 INFO Client: Application report for application_1578014764864_32354 (state: RUNNING)
20/02/27 16:41:35 INFO Client: Application report for application_1578014764864_32354 (state: RUNNING)
20/02/27 16:41:36 INFO Client: Application report for application_1578014764864_32354 (state: RUNNING)
20/02/27 16:41:37 INFO Client: Application report for application_1578014764864_32354 (state: RUNNING)
20/02/27 16:41:38 INFO Client: Application report for application_1578014764864_32354 (state: RUNNING)
20/02/27 16:41:39 INFO Client: Application report for application_1578014764864_32354 (state: RUNNING)
20/02/27 16:41:40 INFO Client: Application report for application_1578014764864_32354 (state: RUNNING)
20/02/27 16:41:42 INFO Client: Application report for application_1578014764864_32354 (state: RUNNING)
20/02/27 16:41:43 INFO Client: Application report for application_1578014764864_32354 (state: RUNNING)
20/02/27 16:41:44 INFO Client: Application report for application_1578014764864_32354 (state: RUNNING)
20/02/27 16:41:45 INFO Client: Application report for application_1578014764864_32354 (state: RUNNING)
20/02/27 16:41:46 INFO Client: Application report for application_1578014764864_32354 (state: RUNNING)
20/02/27 16:41:47 INFO Client: Application report for application_1578014764864_32354 (state: RUNNING)
20/02/27 16:41:48 INFO Client: Application report for application_1578014764864_32354 (state: RUNNING)
20/02/27 16:41:49 INFO Client: Application report for application_1578014764864_32354 (state: RUNNING)
20/02/27 16:41:50 INFO Client: Application report for application_1578014764864_32354 (state: RUNNING)
20/02/27 16:41:51 INFO Client: Application report for application_1578014764864_32354 (state: RUNNING)
20/02/27 16:41:52 INFO Client: Application report for application_1578014764864_32354 (state: RUNNING)
20/02/27 16:41:53 INFO Client: Application report for application_1578014764864_32354 (state: RUNNING)
20/02/27 16:41:54 INFO Client: Application report for application_1578014764864_32354 (state: RUNNING)
20/02/27 16:41:55 INFO Client: Application report for application_1578014764864_32354 (state: RUNNING)
20/02/27 16:41:56 INFO Client: Application report for application_1578014764864_32354 (state: RUNNING)
20/02/27 16:41:57 INFO Client: Application report for application_1578014764864_32354 (state: RUNNING)
20/02/27 16:41:58 INFO Client: Application report for application_1578014764864_32354 (state: RUNNING)
20/02/27 16:41:59 INFO Client: Application report for application_1578014764864_32354 (state: RUNNING)
20/02/27 16:42:00 INFO Client: Application report for application_1578014764864_32354 (state: RUNNING)
20/02/27 16:42:01 INFO Client: Application report for application_1578014764864_32354 (state: RUNNING)
20/02/27 16:42:02 INFO Client: Application report for application_1578014764864_32354 (state: RUNNING)
20/02/27 16:42:03 INFO Client: Application report for application_1578014764864_32354 (state: RUNNING)
20/02/27 16:42:04 INFO Client: Application report for application_1578014764864_32354 (state: RUNNING)
20/02/27 16:42:05 INFO Client: Application report for application_1578014764864_32354 (state: RUNNING)
20/02/27 16:42:06 INFO Client: Application report for application_1578014764864_32354 (state: RUNNING)
20/02/27 16:42:07 INFO Client: Application report for application_1578014764864_32354 (state: RUNNING)
20/02/27 16:42:08 INFO Client: Application report for application_1578014764864_32354 (state: RUNNING)
20/02/27 16:42:09 INFO Client: Application report for application_1578014764864_32354 (state: RUNNING)
20/02/27 16:42:10 INFO Client: Application report for application_1578014764864_32354 (state: RUNNING)
20/02/27 16:42:11 INFO Client: Application report for application_1578014764864_32354 (state: RUNNING)
20/02/27 16:42:12 INFO Client: Application report for application_1578014764864_32354 (state: RUNNING)
20/02/27 16:42:13 INFO Client: Application report for application_1578014764864_32354 (state: RUNNING)
20/02/27 16:42:14 INFO Client: Application report for application_1578014764864_32354 (state: RUNNING)
20/02/27 16:42:15 INFO Client: Application report for application_1578014764864_32354 (state: RUNNING)
20/02/27 16:42:16 INFO Client: Application report for application_1578014764864_32354 (state: RUNNING)
20/02/27 16:42:17 INFO Client: Application report for application_1578014764864_32354 (state: RUNNING)
20/02/27 16:42:18 INFO Client: Application report for application_1578014764864_32354 (state: RUNNING)
20/02/27 16:42:19 INFO Client: Application report for application_1578014764864_32354 (state: RUNNING)
20/02/27 16:42:20 INFO Client: Application report for application_1578014764864_32354 (state: RUNNING)
20/02/27 16:42:21 INFO Client: Application report for application_1578014764864_32354 (state: RUNNING)
20/02/27 16:42:22 INFO Client: Application report for application_1578014764864_32354 (state: RUNNING)
20/02/27 16:42:23 INFO Client: Application report for application_1578014764864_32354 (state: RUNNING)
20/02/27 16:42:24 INFO Client: Application report for application_1578014764864_32354 (state: RUNNING)
20/02/27 16:42:25 INFO Client: Application report for application_1578014764864_32354 (state: RUNNING)
20/02/27 16:42:26 INFO Client: Application report for application_1578014764864_32354 (state: RUNNING)
20/02/27 16:42:27 INFO Client: Application report for application_1578014764864_32354 (state: RUNNING)
20/02/27 16:42:28 INFO Client: Application report for application_1578014764864_32354 (state: RUNNING)
20/02/27 16:42:29 INFO Client: Application report for application_1578014764864_32354 (state: RUNNING)
20/02/27 16:42:30 INFO Client: Application report for application_1578014764864_32354 (state: RUNNING)
20/02/27 16:42:31 INFO Client: Application report for application_1578014764864_32354 (state: RUNNING)
20/02/27 16:42:32 INFO Client: Application report for application_1578014764864_32354 (state: RUNNING)
20/02/27 16:42:33 INFO Client: Application report for application_1578014764864_32354 (state: RUNNING)
20/02/27 16:42:34 INFO Client: Application report for application_1578014764864_32354 (state: RUNNING)
20/02/27 16:42:35 INFO Client: Application report for application_1578014764864_32354 (state: RUNNING)
20/02/27 16:42:36 INFO Client: Application report for application_1578014764864_32354 (state: RUNNING)
20/02/27 16:42:37 INFO Client: Application report for application_1578014764864_32354 (state: RUNNING)
20/02/27 16:42:38 INFO Client: Application report for application_1578014764864_32354 (state: RUNNING)
20/02/27 16:42:39 INFO Client: Application report for application_1578014764864_32354 (state: RUNNING)
20/02/27 16:42:40 INFO Client: Application report for application_1578014764864_32354 (state: RUNNING)
20/02/27 16:42:41 INFO Client: Application report for application_1578014764864_32354 (state: RUNNING)
20/02/27 16:42:42 INFO Client: Application report for application_1578014764864_32354 (state: RUNNING)
20/02/27 16:42:43 INFO Client: Application report for application_1578014764864_32354 (state: RUNNING)
20/02/27 16:42:44 INFO Client: Application report for application_1578014764864_32354 (state: RUNNING)
20/02/27 16:42:45 INFO Client: Application report for application_1578014764864_32354 (state: RUNNING)
20/02/27 16:42:46 INFO Client: Application report for application_1578014764864_32354 (state: RUNNING)
20/02/27 16:42:47 INFO Client: Application report for application_1578014764864_32354 (state: RUNNING)
20/02/27 16:42:48 INFO Client: Application report for application_1578014764864_32354 (state: RUNNING)
20/02/27 16:42:49 INFO Client: Application report for application_1578014764864_32354 (state: RUNNING)
20/02/27 16:42:50 INFO Client: Application report for application_1578014764864_32354 (state: RUNNING)
20/02/27 16:42:51 INFO Client: Application report for application_1578014764864_32354 (state: RUNNING)
20/02/27 16:42:52 INFO Client: Application report for application_1578014764864_32354 (state: RUNNING)
20/02/27 16:42:53 INFO Client: Application report for application_1578014764864_32354 (state: RUNNING)
20/02/27 16:42:54 INFO Client: Application report for application_1578014764864_32354 (state: RUNNING)
20/02/27 16:42:55 INFO Client: Application report for application_1578014764864_32354 (state: RUNNING)
20/02/27 16:42:56 INFO Client: Application report for application_1578014764864_32354 (state: RUNNING)
20/02/27 16:42:57 INFO Client: Application report for application_1578014764864_32354 (state: RUNNING)
20/02/27 16:42:58 INFO Client: Application report for application_1578014764864_32354 (state: RUNNING)
20/02/27 16:42:59 INFO Client: Application report for application_1578014764864_32354 (state: RUNNING)
20/02/27 16:43:00 INFO Client: Application report for application_1578014764864_32354 (state: RUNNING)
20/02/27 16:43:01 INFO Client: Application report for application_1578014764864_32354 (state: RUNNING)
20/02/27 16:43:02 INFO Client: Application report for application_1578014764864_32354 (state: RUNNING)
20/02/27 16:43:03 INFO Client: Application report for application_1578014764864_32354 (state: RUNNING)
20/02/27 16:43:04 INFO Client: Application report for application_1578014764864_32354 (state: RUNNING)
20/02/27 16:43:05 INFO Client: Application report for application_1578014764864_32354 (state: RUNNING)
20/02/27 16:43:06 INFO Client: Application report for application_1578014764864_32354 (state: RUNNING)
20/02/27 16:43:07 INFO Client: Application report for application_1578014764864_32354 (state: RUNNING)
20/02/27 16:43:08 INFO Client: Application report for application_1578014764864_32354 (state: RUNNING)
20/02/27 16:43:09 INFO Client: Application report for application_1578014764864_32354 (state: RUNNING)
20/02/27 16:43:10 INFO Client: Application report for application_1578014764864_32354 (state: RUNNING)
20/02/27 16:43:11 INFO Client: Application report for application_1578014764864_32354 (state: RUNNING)
20/02/27 16:43:12 INFO Client: Application report for application_1578014764864_32354 (state: RUNNING)
20/02/27 16:43:13 INFO Client: Application report for application_1578014764864_32354 (state: RUNNING)
20/02/27 16:43:14 INFO Client: Application report for application_1578014764864_32354 (state: RUNNING)
20/02/27 16:43:15 INFO Client: Application report for application_1578014764864_32354 (state: RUNNING)
20/02/27 16:43:16 INFO Client: Application report for application_1578014764864_32354 (state: RUNNING)
20/02/27 16:43:17 INFO Client: Application report for application_1578014764864_32354 (state: RUNNING)
20/02/27 16:43:18 INFO Client: Application report for application_1578014764864_32354 (state: RUNNING)
20/02/27 16:43:19 INFO Client: Application report for application_1578014764864_32354 (state: RUNNING)
20/02/27 16:43:20 INFO Client: Application report for application_1578014764864_32354 (state: RUNNING)
20/02/27 16:43:21 INFO Client: Application report for application_1578014764864_32354 (state: RUNNING)
20/02/27 16:43:22 INFO Client: Application report for application_1578014764864_32354 (state: RUNNING)
20/02/27 16:43:23 INFO Client: Application report for application_1578014764864_32354 (state: RUNNING)
20/02/27 16:43:24 INFO Client: Application report for application_1578014764864_32354 (state: RUNNING)
20/02/27 16:43:25 INFO Client: Application report for application_1578014764864_32354 (state: RUNNING)
20/02/27 16:43:26 INFO Client: Application report for application_1578014764864_32354 (state: RUNNING)
20/02/27 16:43:27 INFO Client: Application report for application_1578014764864_32354 (state: RUNNING)
20/02/27 16:43:28 INFO Client: Application report for application_1578014764864_32354 (state: RUNNING)
20/02/27 16:43:29 INFO Client: Application report for application_1578014764864_32354 (state: RUNNING)
20/02/27 16:43:30 INFO Client: Application report for application_1578014764864_32354 (state: RUNNING)
20/02/27 16:43:31 INFO Client: Application report for application_1578014764864_32354 (state: RUNNING)
20/02/27 16:43:32 INFO Client: Application report for application_1578014764864_32354 (state: RUNNING)
20/02/27 16:43:33 INFO Client: Application report for application_1578014764864_32354 (state: RUNNING)
20/02/27 16:43:34 INFO Client: Application report for application_1578014764864_32354 (state: RUNNING)
20/02/27 16:43:35 INFO Client: Application report for application_1578014764864_32354 (state: RUNNING)
20/02/27 16:43:36 INFO Client: Application report for application_1578014764864_32354 (state: RUNNING)
20/02/27 16:43:37 INFO Client: Application report for application_1578014764864_32354 (state: RUNNING)
20/02/27 16:43:38 INFO Client: Application report for application_1578014764864_32354 (state: RUNNING)
20/02/27 16:43:39 INFO Client: Application report for application_1578014764864_32354 (state: RUNNING)
20/02/27 16:43:40 INFO Client: Application report for application_1578014764864_32354 (state: RUNNING)
20/02/27 16:43:41 INFO Client: Application report for application_1578014764864_32354 (state: RUNNING)
20/02/27 16:43:42 INFO Client: Application report for application_1578014764864_32354 (state: RUNNING)
20/02/27 16:43:43 INFO Client: Application report for application_1578014764864_32354 (state: RUNNING)
20/02/27 16:43:44 INFO Client: Application report for application_1578014764864_32354 (state: RUNNING)
20/02/27 16:43:45 INFO Client: Application report for application_1578014764864_32354 (state: RUNNING)
20/02/27 16:43:46 INFO Client: Application report for application_1578014764864_32354 (state: RUNNING)
20/02/27 16:43:47 INFO Client: Application report for application_1578014764864_32354 (state: RUNNING)
20/02/27 16:43:48 INFO Client: Application report for application_1578014764864_32354 (state: RUNNING)
20/02/27 16:43:49 INFO Client: Application report for application_1578014764864_32354 (state: RUNNING)
20/02/27 16:43:50 INFO Client: Application report for application_1578014764864_32354 (state: RUNNING)
20/02/27 16:43:51 INFO Client: Application report for application_1578014764864_32354 (state: RUNNING)
20/02/27 16:43:52 INFO Client: Application report for application_1578014764864_32354 (state: RUNNING)
20/02/27 16:43:53 INFO Client: Application report for application_1578014764864_32354 (state: RUNNING)
20/02/27 16:43:54 INFO Client: Application report for application_1578014764864_32354 (state: RUNNING)
20/02/27 16:43:55 INFO Client: Application report for application_1578014764864_32354 (state: RUNNING)
20/02/27 16:43:56 INFO Client: Application report for application_1578014764864_32354 (state: RUNNING)
20/02/27 16:43:57 INFO Client: Application report for application_1578014764864_32354 (state: RUNNING)
20/02/27 16:43:58 INFO Client: Application report for application_1578014764864_32354 (state: RUNNING)
20/02/27 16:43:59 INFO Client: Application report for application_1578014764864_32354 (state: RUNNING)
20/02/27 16:44:00 INFO Client: Application report for application_1578014764864_32354 (state: RUNNING)
20/02/27 16:44:01 INFO Client: Application report for application_1578014764864_32354 (state: RUNNING)
20/02/27 16:44:02 INFO Client: Application report for application_1578014764864_32354 (state: RUNNING)
20/02/27 16:44:03 INFO Client: Application report for application_1578014764864_32354 (state: RUNNING)
20/02/27 16:44:04 INFO Client: Application report for application_1578014764864_32354 (state: RUNNING)
20/02/27 16:44:05 INFO Client: Application report for application_1578014764864_32354 (state: RUNNING)
20/02/27 16:44:06 INFO Client: Application report for application_1578014764864_32354 (state: RUNNING)
20/02/27 16:44:07 INFO Client: Application report for application_1578014764864_32354 (state: RUNNING)
20/02/27 16:44:08 INFO Client: Application report for application_1578014764864_32354 (state: RUNNING)
20/02/27 16:44:09 INFO Client: Application report for application_1578014764864_32354 (state: ACCEPTED)
20/02/27 16:44:09 INFO Client: 
	 client token: N/A
	 diagnostics: AM container is launched, waiting for AM container to Register with RM
	 ApplicationMaster host: N/A
	 ApplicationMaster RPC port: -1
	 queue: default
	 start time: 1582821683950
	 final status: UNDEFINED
	 tracking URL: http://ip-10-84-38-68.corp.stateauto.com:20888/proxy/application_1578014764864_32354/
	 user: hadoop
20/02/27 16:44:10 INFO Client: Application report for application_1578014764864_32354 (state: ACCEPTED)
20/02/27 16:44:11 INFO Client: Application report for application_1578014764864_32354 (state: ACCEPTED)
20/02/27 16:44:12 INFO Client: Application report for application_1578014764864_32354 (state: ACCEPTED)
20/02/27 16:44:13 INFO Client: Application report for application_1578014764864_32354 (state: ACCEPTED)
20/02/27 16:44:14 INFO Client: Application report for application_1578014764864_32354 (state: RUNNING)
20/02/27 16:44:14 INFO Client: 
	 client token: N/A
	 diagnostics: N/A
	 ApplicationMaster host: ip-10-84-36-42.corp.stateauto.com
	 ApplicationMaster RPC port: 43247
	 queue: default
	 start time: 1582821683950
	 final status: UNDEFINED
	 tracking URL: http://ip-10-84-38-68.corp.stateauto.com:20888/proxy/application_1578014764864_32354/
	 user: hadoop
20/02/27 16:44:15 INFO Client: Application report for application_1578014764864_32354 (state: RUNNING)
20/02/27 16:44:16 INFO Client: Application report for application_1578014764864_32354 (state: RUNNING)
20/02/27 16:44:17 INFO Client: Application report for application_1578014764864_32354 (state: RUNNING)
20/02/27 16:44:18 INFO Client: Application report for application_1578014764864_32354 (state: RUNNING)
20/02/27 16:44:19 INFO Client: Application report for application_1578014764864_32354 (state: RUNNING)
20/02/27 16:44:20 INFO Client: Application report for application_1578014764864_32354 (state: RUNNING)
20/02/27 16:44:21 INFO Client: Application report for application_1578014764864_32354 (state: RUNNING)
20/02/27 16:44:22 INFO Client: Application report for application_1578014764864_32354 (state: RUNNING)
20/02/27 16:44:23 INFO Client: Application report for application_1578014764864_32354 (state: RUNNING)
20/02/27 16:44:24 INFO Client: Application report for application_1578014764864_32354 (state: RUNNING)
20/02/27 16:44:25 INFO Client: Application report for application_1578014764864_32354 (state: RUNNING)
20/02/27 16:44:26 INFO Client: Application report for application_1578014764864_32354 (state: RUNNING)
20/02/27 16:44:27 INFO Client: Application report for application_1578014764864_32354 (state: RUNNING)
20/02/27 16:44:28 INFO Client: Application report for application_1578014764864_32354 (state: RUNNING)
20/02/27 16:44:29 INFO Client: Application report for application_1578014764864_32354 (state: RUNNING)
20/02/27 16:44:30 INFO Client: Application report for application_1578014764864_32354 (state: RUNNING)
20/02/27 16:44:31 INFO Client: Application report for application_1578014764864_32354 (state: RUNNING)
20/02/27 16:44:32 INFO Client: Application report for application_1578014764864_32354 (state: RUNNING)
20/02/27 16:44:33 INFO Client: Application report for application_1578014764864_32354 (state: RUNNING)
20/02/27 16:44:34 INFO Client: Application report for application_1578014764864_32354 (state: RUNNING)
20/02/27 16:44:35 INFO Client: Application report for application_1578014764864_32354 (state: RUNNING)
20/02/27 16:44:36 INFO Client: Application report for application_1578014764864_32354 (state: RUNNING)
20/02/27 16:44:37 INFO Client: Application report for application_1578014764864_32354 (state: RUNNING)
20/02/27 16:44:38 INFO Client: Application report for application_1578014764864_32354 (state: RUNNING)
20/02/27 16:44:39 INFO Client: Application report for application_1578014764864_32354 (state: RUNNING)
20/02/27 16:44:40 INFO Client: Application report for application_1578014764864_32354 (state: RUNNING)
20/02/27 16:44:41 INFO Client: Application report for application_1578014764864_32354 (state: RUNNING)
20/02/27 16:44:42 INFO Client: Application report for application_1578014764864_32354 (state: RUNNING)
20/02/27 16:44:43 INFO Client: Application report for application_1578014764864_32354 (state: RUNNING)
20/02/27 16:44:44 INFO Client: Application report for application_1578014764864_32354 (state: RUNNING)
20/02/27 16:44:45 INFO Client: Application report for application_1578014764864_32354 (state: RUNNING)
20/02/27 16:44:46 INFO Client: Application report for application_1578014764864_32354 (state: RUNNING)
20/02/27 16:44:47 INFO Client: Application report for application_1578014764864_32354 (state: RUNNING)
20/02/27 16:44:48 INFO Client: Application report for application_1578014764864_32354 (state: RUNNING)
20/02/27 16:44:49 INFO Client: Application report for application_1578014764864_32354 (state: RUNNING)
20/02/27 16:44:50 INFO Client: Application report for application_1578014764864_32354 (state: RUNNING)
20/02/27 16:44:51 INFO Client: Application report for application_1578014764864_32354 (state: RUNNING)
20/02/27 16:44:52 INFO Client: Application report for application_1578014764864_32354 (state: RUNNING)
20/02/27 16:44:53 INFO Client: Application report for application_1578014764864_32354 (state: RUNNING)
20/02/27 16:44:54 INFO Client: Application report for application_1578014764864_32354 (state: RUNNING)
20/02/27 16:44:55 INFO Client: Application report for application_1578014764864_32354 (state: RUNNING)
20/02/27 16:44:56 INFO Client: Application report for application_1578014764864_32354 (state: RUNNING)
20/02/27 16:44:57 INFO Client: Application report for application_1578014764864_32354 (state: RUNNING)
20/02/27 16:44:58 INFO Client: Application report for application_1578014764864_32354 (state: RUNNING)
20/02/27 16:44:59 INFO Client: Application report for application_1578014764864_32354 (state: RUNNING)
20/02/27 16:45:00 INFO Client: Application report for application_1578014764864_32354 (state: RUNNING)
20/02/27 16:45:01 INFO Client: Application report for application_1578014764864_32354 (state: RUNNING)
20/02/27 16:45:02 INFO Client: Application report for application_1578014764864_32354 (state: RUNNING)
20/02/27 16:45:03 INFO Client: Application report for application_1578014764864_32354 (state: RUNNING)
20/02/27 16:45:04 INFO Client: Application report for application_1578014764864_32354 (state: RUNNING)
20/02/27 16:45:05 INFO Client: Application report for application_1578014764864_32354 (state: RUNNING)
20/02/27 16:45:06 INFO Client: Application report for application_1578014764864_32354 (state: RUNNING)
20/02/27 16:45:07 INFO Client: Application report for application_1578014764864_32354 (state: RUNNING)
20/02/27 16:45:08 INFO Client: Application report for application_1578014764864_32354 (state: RUNNING)
20/02/27 16:45:09 INFO Client: Application report for application_1578014764864_32354 (state: RUNNING)
20/02/27 16:45:10 INFO Client: Application report for application_1578014764864_32354 (state: RUNNING)
20/02/27 16:45:11 INFO Client: Application report for application_1578014764864_32354 (state: RUNNING)
20/02/27 16:45:12 INFO Client: Application report for application_1578014764864_32354 (state: RUNNING)
20/02/27 16:45:13 INFO Client: Application report for application_1578014764864_32354 (state: RUNNING)
20/02/27 16:45:14 INFO Client: Application report for application_1578014764864_32354 (state: RUNNING)
20/02/27 16:45:15 INFO Client: Application report for application_1578014764864_32354 (state: RUNNING)
20/02/27 16:45:16 INFO Client: Application report for application_1578014764864_32354 (state: RUNNING)
20/02/27 16:45:17 INFO Client: Application report for application_1578014764864_32354 (state: RUNNING)
20/02/27 16:45:18 INFO Client: Application report for application_1578014764864_32354 (state: RUNNING)
20/02/27 16:45:19 INFO Client: Application report for application_1578014764864_32354 (state: RUNNING)
20/02/27 16:45:20 INFO Client: Application report for application_1578014764864_32354 (state: RUNNING)
20/02/27 16:45:21 INFO Client: Application report for application_1578014764864_32354 (state: RUNNING)
20/02/27 16:45:22 INFO Client: Application report for application_1578014764864_32354 (state: RUNNING)
20/02/27 16:45:23 INFO Client: Application report for application_1578014764864_32354 (state: RUNNING)
20/02/27 16:45:24 INFO Client: Application report for application_1578014764864_32354 (state: RUNNING)
20/02/27 16:45:25 INFO Client: Application report for application_1578014764864_32354 (state: RUNNING)
20/02/27 16:45:26 INFO Client: Application report for application_1578014764864_32354 (state: RUNNING)
20/02/27 16:45:27 INFO Client: Application report for application_1578014764864_32354 (state: RUNNING)
20/02/27 16:45:28 INFO Client: Application report for application_1578014764864_32354 (state: RUNNING)
20/02/27 16:45:29 INFO Client: Application report for application_1578014764864_32354 (state: RUNNING)
20/02/27 16:45:30 INFO Client: Application report for application_1578014764864_32354 (state: RUNNING)
20/02/27 16:45:31 INFO Client: Application report for application_1578014764864_32354 (state: RUNNING)
20/02/27 16:45:32 INFO Client: Application report for application_1578014764864_32354 (state: RUNNING)
20/02/27 16:45:33 INFO Client: Application report for application_1578014764864_32354 (state: RUNNING)
20/02/27 16:45:34 INFO Client: Application report for application_1578014764864_32354 (state: RUNNING)
20/02/27 16:45:35 INFO Client: Application report for application_1578014764864_32354 (state: RUNNING)
20/02/27 16:45:36 INFO Client: Application report for application_1578014764864_32354 (state: RUNNING)
20/02/27 16:45:37 INFO Client: Application report for application_1578014764864_32354 (state: RUNNING)
20/02/27 16:45:38 INFO Client: Application report for application_1578014764864_32354 (state: RUNNING)
20/02/27 16:45:39 INFO Client: Application report for application_1578014764864_32354 (state: RUNNING)
20/02/27 16:45:40 INFO Client: Application report for application_1578014764864_32354 (state: RUNNING)
20/02/27 16:45:41 INFO Client: Application report for application_1578014764864_32354 (state: RUNNING)
20/02/27 16:45:42 INFO Client: Application report for application_1578014764864_32354 (state: RUNNING)
20/02/27 16:45:43 INFO Client: Application report for application_1578014764864_32354 (state: RUNNING)
20/02/27 16:45:44 INFO Client: Application report for application_1578014764864_32354 (state: RUNNING)
20/02/27 16:45:45 INFO Client: Application report for application_1578014764864_32354 (state: RUNNING)
20/02/27 16:45:46 INFO Client: Application report for application_1578014764864_32354 (state: RUNNING)
20/02/27 16:45:47 INFO Client: Application report for application_1578014764864_32354 (state: RUNNING)
20/02/27 16:45:48 INFO Client: Application report for application_1578014764864_32354 (state: RUNNING)
20/02/27 16:45:49 INFO Client: Application report for application_1578014764864_32354 (state: RUNNING)
20/02/27 16:45:50 INFO Client: Application report for application_1578014764864_32354 (state: RUNNING)
20/02/27 16:45:51 INFO Client: Application report for application_1578014764864_32354 (state: RUNNING)
20/02/27 16:45:52 INFO Client: Application report for application_1578014764864_32354 (state: RUNNING)
20/02/27 16:45:53 INFO Client: Application report for application_1578014764864_32354 (state: RUNNING)
20/02/27 16:45:54 INFO Client: Application report for application_1578014764864_32354 (state: RUNNING)
20/02/27 16:45:55 INFO Client: Application report for application_1578014764864_32354 (state: RUNNING)
20/02/27 16:45:56 INFO Client: Application report for application_1578014764864_32354 (state: RUNNING)
20/02/27 16:45:57 INFO Client: Application report for application_1578014764864_32354 (state: RUNNING)
20/02/27 16:45:58 INFO Client: Application report for application_1578014764864_32354 (state: RUNNING)
20/02/27 16:45:59 INFO Client: Application report for application_1578014764864_32354 (state: RUNNING)
20/02/27 16:46:00 INFO Client: Application report for application_1578014764864_32354 (state: RUNNING)
20/02/27 16:46:01 INFO Client: Application report for application_1578014764864_32354 (state: RUNNING)
20/02/27 16:46:02 INFO Client: Application report for application_1578014764864_32354 (state: RUNNING)
20/02/27 16:46:03 INFO Client: Application report for application_1578014764864_32354 (state: RUNNING)
20/02/27 16:46:04 INFO Client: Application report for application_1578014764864_32354 (state: RUNNING)
20/02/27 16:46:05 INFO Client: Application report for application_1578014764864_32354 (state: RUNNING)
20/02/27 16:46:06 INFO Client: Application report for application_1578014764864_32354 (state: RUNNING)
20/02/27 16:46:07 INFO Client: Application report for application_1578014764864_32354 (state: RUNNING)
20/02/27 16:46:08 INFO Client: Application report for application_1578014764864_32354 (state: RUNNING)
20/02/27 16:46:09 INFO Client: Application report for application_1578014764864_32354 (state: RUNNING)
20/02/27 16:46:10 INFO Client: Application report for application_1578014764864_32354 (state: RUNNING)
20/02/27 16:46:11 INFO Client: Application report for application_1578014764864_32354 (state: RUNNING)
20/02/27 16:46:12 INFO Client: Application report for application_1578014764864_32354 (state: RUNNING)
20/02/27 16:46:13 INFO Client: Application report for application_1578014764864_32354 (state: RUNNING)
20/02/27 16:46:14 INFO Client: Application report for application_1578014764864_32354 (state: RUNNING)
20/02/27 16:46:15 INFO Client: Application report for application_1578014764864_32354 (state: RUNNING)
20/02/27 16:46:16 INFO Client: Application report for application_1578014764864_32354 (state: RUNNING)
20/02/27 16:46:17 INFO Client: Application report for application_1578014764864_32354 (state: RUNNING)
20/02/27 16:46:18 INFO Client: Application report for application_1578014764864_32354 (state: RUNNING)
20/02/27 16:46:19 INFO Client: Application report for application_1578014764864_32354 (state: RUNNING)
20/02/27 16:46:20 INFO Client: Application report for application_1578014764864_32354 (state: RUNNING)
20/02/27 16:46:21 INFO Client: Application report for application_1578014764864_32354 (state: RUNNING)
20/02/27 16:46:22 INFO Client: Application report for application_1578014764864_32354 (state: RUNNING)
20/02/27 16:46:23 INFO Client: Application report for application_1578014764864_32354 (state: RUNNING)
20/02/27 16:46:24 INFO Client: Application report for application_1578014764864_32354 (state: RUNNING)
20/02/27 16:46:25 INFO Client: Application report for application_1578014764864_32354 (state: RUNNING)
20/02/27 16:46:26 INFO Client: Application report for application_1578014764864_32354 (state: RUNNING)
20/02/27 16:46:27 INFO Client: Application report for application_1578014764864_32354 (state: RUNNING)
20/02/27 16:46:28 INFO Client: Application report for application_1578014764864_32354 (state: RUNNING)
20/02/27 16:46:29 INFO Client: Application report for application_1578014764864_32354 (state: RUNNING)
20/02/27 16:46:30 INFO Client: Application report for application_1578014764864_32354 (state: RUNNING)
20/02/27 16:46:31 INFO Client: Application report for application_1578014764864_32354 (state: RUNNING)
20/02/27 16:46:32 INFO Client: Application report for application_1578014764864_32354 (state: RUNNING)
20/02/27 16:46:33 INFO Client: Application report for application_1578014764864_32354 (state: RUNNING)
20/02/27 16:46:34 INFO Client: Application report for application_1578014764864_32354 (state: RUNNING)
20/02/27 16:46:35 INFO Client: Application report for application_1578014764864_32354 (state: RUNNING)
20/02/27 16:46:36 INFO Client: Application report for application_1578014764864_32354 (state: RUNNING)
20/02/27 16:46:37 INFO Client: Application report for application_1578014764864_32354 (state: RUNNING)
20/02/27 16:46:38 INFO Client: Application report for application_1578014764864_32354 (state: RUNNING)
20/02/27 16:46:39 INFO Client: Application report for application_1578014764864_32354 (state: RUNNING)
20/02/27 16:46:40 INFO Client: Application report for application_1578014764864_32354 (state: RUNNING)
20/02/27 16:46:41 INFO Client: Application report for application_1578014764864_32354 (state: RUNNING)
20/02/27 16:46:42 INFO Client: Application report for application_1578014764864_32354 (state: RUNNING)
20/02/27 16:46:43 INFO Client: Application report for application_1578014764864_32354 (state: RUNNING)
20/02/27 16:46:44 INFO Client: Application report for application_1578014764864_32354 (state: FINISHED)
20/02/27 16:46:44 INFO Client: 
	 client token: N/A
	 diagnostics: User class threw exception: org.apache.spark.SparkException: Job aborted due to stage failure: Task 99 in stage 110.0 failed 4 times, most recent failure: Lost task 99.3 in stage 110.0 (TID 13297, ip-10-84-46-117.corp.stateauto.com, executor 26): java.io.IOException: com.amazon.ws.emr.hadoop.fs.shaded.com.amazonaws.services.s3.model.AmazonS3Exception: Slow Down (Service: Amazon S3; Status Code: 503; Error Code: 503 Slow Down; Request ID: 7224C1654622C38F; S3 Extended Request ID: kDTVvl0rvOdetv3FAhsaXCnbpHcLfIFE2D4G+hQKDKGcZ3IiM5EMGZQ5UYGiZvBSLnZ3OvjkMXY=), S3 Extended Request ID: kDTVvl0rvOdetv3FAhsaXCnbpHcLfIFE2D4G+hQKDKGcZ3IiM5EMGZQ5UYGiZvBSLnZ3OvjkMXY=
	at com.amazon.ws.emr.hadoop.fs.s3n2.S3NativeFileSystem2.listStatus(S3NativeFileSystem2.java:237)
	at com.amazon.ws.emr.hadoop.fs.EmrFileSystem.listStatus(EmrFileSystem.java:373)
	at org.apache.spark.sql.execution.datasources.InMemoryFileIndex$.org$apache$spark$sql$execution$datasources$InMemoryFileIndex$$listLeafFiles(InMemoryFileIndex.scala:277)
	at org.apache.spark.sql.execution.datasources.InMemoryFileIndex$$anonfun$3$$anonfun$apply$2.apply(InMemoryFileIndex.scala:207)
	at org.apache.spark.sql.execution.datasources.InMemoryFileIndex$$anonfun$3$$anonfun$apply$2.apply(InMemoryFileIndex.scala:206)
	at scala.collection.immutable.Stream.map(Stream.scala:418)
	at org.apache.spark.sql.execution.datasources.InMemoryFileIndex$$anonfun$3.apply(InMemoryFileIndex.scala:206)
	at org.apache.spark.sql.execution.datasources.InMemoryFileIndex$$anonfun$3.apply(InMemoryFileIndex.scala:204)
	at org.apache.spark.rdd.RDD$$anonfun$mapPartitions$1$$anonfun$apply$23.apply(RDD.scala:801)
	at org.apache.spark.rdd.RDD$$anonfun$mapPartitions$1$$anonfun$apply$23.apply(RDD.scala:801)
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:324)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:288)
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:324)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:288)
	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90)
	at org.apache.spark.scheduler.Task.run(Task.scala:121)
	at org.apache.spark.executor.Executor$TaskRunner$$anonfun$10.apply(Executor.scala:402)
	at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1360)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:408)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
Caused by: com.amazon.ws.emr.hadoop.fs.shaded.com.amazonaws.services.s3.model.AmazonS3Exception: Slow Down (Service: Amazon S3; Status Code: 503; Error Code: 503 Slow Down; Request ID: 7224C1654622C38F; S3 Extended Request ID: kDTVvl0rvOdetv3FAhsaXCnbpHcLfIFE2D4G+hQKDKGcZ3IiM5EMGZQ5UYGiZvBSLnZ3OvjkMXY=), S3 Extended Request ID: kDTVvl0rvOdetv3FAhsaXCnbpHcLfIFE2D4G+hQKDKGcZ3IiM5EMGZQ5UYGiZvBSLnZ3OvjkMXY=
	at com.amazon.ws.emr.hadoop.fs.shaded.com.amazonaws.http.AmazonHttpClient$RequestExecutor.handleErrorResponse(AmazonHttpClient.java:1658)
	at com.amazon.ws.emr.hadoop.fs.shaded.com.amazonaws.http.AmazonHttpClient$RequestExecutor.executeOneRequest(AmazonHttpClient.java:1322)
	at com.amazon.ws.emr.hadoop.fs.shaded.com.amazonaws.http.AmazonHttpClient$RequestExecutor.executeHelper(AmazonHttpClient.java:1072)
	at com.amazon.ws.emr.hadoop.fs.shaded.com.amazonaws.http.AmazonHttpClient$RequestExecutor.doExecute(AmazonHttpClient.java:745)
	at com.amazon.ws.emr.hadoop.fs.shaded.com.amazonaws.http.AmazonHttpClient$RequestExecutor.executeWithTimer(AmazonHttpClient.java:719)
	at com.amazon.ws.emr.hadoop.fs.shaded.com.amazonaws.http.AmazonHttpClient$RequestExecutor.execute(AmazonHttpClient.java:701)
	at com.amazon.ws.emr.hadoop.fs.shaded.com.amazonaws.http.AmazonHttpClient$RequestExecutor.access$500(AmazonHttpClient.java:669)
	at com.amazon.ws.emr.hadoop.fs.shaded.com.amazonaws.http.AmazonHttpClient$RequestExecutionBuilderImpl.execute(AmazonHttpClient.java:651)
	at com.amazon.ws.emr.hadoop.fs.shaded.com.amazonaws.http.AmazonHttpClient.execute(AmazonHttpClient.java:515)
	at com.amazon.ws.emr.hadoop.fs.shaded.com.amazonaws.services.s3.AmazonS3Client.invoke(AmazonS3Client.java:4443)
	at com.amazon.ws.emr.hadoop.fs.shaded.com.amazonaws.services.s3.AmazonS3Client.invoke(AmazonS3Client.java:4390)
	at com.amazon.ws.emr.hadoop.fs.shaded.com.amazonaws.services.s3.AmazonS3Client.getObjectMetadata(AmazonS3Client.java:1280)
	at com.amazon.ws.emr.hadoop.fs.s3.lite.call.GetObjectMetadataCall.perform(GetObjectMetadataCall.java:22)
	at com.amazon.ws.emr.hadoop.fs.s3.lite.call.GetObjectMetadataCall.perform(GetObjectMetadataCall.java:8)
	at com.amazon.ws.emr.hadoop.fs.s3.lite.executor.GlobalS3Executor.execute(GlobalS3Executor.java:91)
	at com.amazon.ws.emr.hadoop.fs.s3.lite.AmazonS3LiteClient.invoke(AmazonS3LiteClient.java:184)
	at com.amazon.ws.emr.hadoop.fs.s3.lite.AmazonS3LiteClient.getObjectMetadata(AmazonS3LiteClient.java:96)
	at com.amazon.ws.emr.hadoop.fs.consistency.ConsistencyCheckerS3FileSystem.getObjectMetadata(ConsistencyCheckerS3FileSystem.java:973)
	at com.amazon.ws.emr.hadoop.fs.consistency.ConsistencyCheckerS3FileSystem.getFileStatusFromS3CheckingConsistencyIfEnabled(ConsistencyCheckerS3FileSystem.java:439)
	at com.amazon.ws.emr.hadoop.fs.consistency.ConsistencyCheckerS3FileSystem.getFileStatus(ConsistencyCheckerS3FileSystem.java:406)
	at com.amazon.ws.emr.hadoop.fs.consistency.ConsistencyCheckerS3FileSystem.getFileStatus(ConsistencyCheckerS3FileSystem.java:399)
	at com.amazon.ws.emr.hadoop.fs.consistency.ConsistencyCheckerS3FileSystem.listStatus(ConsistencyCheckerS3FileSystem.java:510)
	at sun.reflect.GeneratedMethodAccessor58.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:409)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invokeMethod(RetryInvocationHandler.java:163)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invoke(RetryInvocationHandler.java:155)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invokeOnce(RetryInvocationHandler.java:95)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:346)
	at com.sun.proxy.$Proxy37.listStatus(Unknown Source)
	at com.amazon.ws.emr.hadoop.fs.s3n2.S3NativeFileSystem2.listStatus(S3NativeFileSystem2.java:224)
	... 23 more

Driver stacktrace:
	at org.apache.spark.scheduler.DAGScheduler.org$apache$spark$scheduler$DAGScheduler$$failJobAndIndependentStages(DAGScheduler.scala:2039)
	at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:2027)
	at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:2026)
	at scala.collection.mutable.ResizableArray$class.foreach(ResizableArray.scala:59)
	at scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:48)
	at org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:2026)
	at org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:966)
	at org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:966)
	at scala.Option.foreach(Option.scala:257)
	at org.apache.spark.scheduler.DAGScheduler.handleTaskSetFailed(DAGScheduler.scala:966)
	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.doOnReceive(DAGScheduler.scala:2260)
	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:2209)
	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:2198)
	at org.apache.spark.util.EventLoop$$anon$1.run(EventLoop.scala:49)
	at org.apache.spark.scheduler.DAGScheduler.runJob(DAGScheduler.scala:777)
	at org.apache.spark.SparkContext.runJob(SparkContext.scala:2061)
	at org.apache.spark.SparkContext.runJob(SparkContext.scala:2082)
	at org.apache.spark.SparkContext.runJob(SparkContext.scala:2101)
	at org.apache.spark.SparkContext.runJob(SparkContext.scala:2126)
	at org.apache.spark.rdd.RDD$$anonfun$collect$1.apply(RDD.scala:945)
	at org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:151)
	at org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:112)
	at org.apache.spark.rdd.RDD.withScope(RDD.scala:363)
	at org.apache.spark.rdd.RDD.collect(RDD.scala:944)
	at org.apache.spark.sql.execution.datasources.InMemoryFileIndex$.bulkListLeafFiles(InMemoryFileIndex.scala:237)
	at org.apache.spark.sql.execution.datasources.InMemoryFileIndex.listLeafFiles(InMemoryFileIndex.scala:126)
	at org.apache.spark.sql.execution.datasources.InMemoryFileIndex.refresh0(InMemoryFileIndex.scala:91)
	at org.apache.spark.sql.execution.datasources.InMemoryFileIndex.<init>(InMemoryFileIndex.scala:67)
	at org.apache.spark.sql.execution.datasources.PrunedInMemoryFileIndex.<init>(CatalogFileIndex.scala:118)
	at org.apache.spark.sql.execution.datasources.CatalogFileIndex.filterPartitions(CatalogFileIndex.scala:84)
	at org.apache.spark.sql.execution.datasources.CatalogFileIndex.listFiles(CatalogFileIndex.scala:59)
	at org.apache.spark.sql.execution.FileSourceScanExec.org$apache$spark$sql$execution$FileSourceScanExec$$selectedPartitions$lzycompute(DataSourceScanExec.scala:191)
	at org.apache.spark.sql.execution.FileSourceScanExec.org$apache$spark$sql$execution$FileSourceScanExec$$selectedPartitions(DataSourceScanExec.scala:188)
	at org.apache.spark.sql.execution.FileSourceScanExec$$anonfun$22.apply(DataSourceScanExec.scala:290)
	at org.apache.spark.sql.execution.FileSourceScanExec$$anonfun$22.apply(DataSourceScanExec.scala:289)
	at scala.Option.map(Option.scala:146)
	at org.apache.spark.sql.execution.FileSourceScanExec.metadata$lzycompute(DataSourceScanExec.scala:289)
	at org.apache.spark.sql.execution.FileSourceScanExec.metadata(DataSourceScanExec.scala:275)
	at org.apache.spark.sql.execution.DataSourceScanExec$class.simpleString(DataSourceScanExec.scala:55)
	at org.apache.spark.sql.execution.FileSourceScanExec.simpleString(DataSourceScanExec.scala:159)
	at org.apache.spark.sql.catalyst.plans.QueryPlan.verboseString(QueryPlan.scala:177)
	at org.apache.spark.sql.execution.FileSourceScanExec.org$apache$spark$sql$execution$DataSourceScanExec$$super$verboseString(DataSourceScanExec.scala:159)
	at org.apache.spark.sql.execution.DataSourceScanExec$class.verboseString(DataSourceScanExec.scala:63)
	at org.apache.spark.sql.execution.FileSourceScanExec.verboseString(DataSourceScanExec.scala:159)
	at org.apache.spark.sql.catalyst.trees.TreeNode.generateTreeString(TreeNode.scala:548)
	at org.apache.spark.sql.catalyst.trees.TreeNode.generateTreeString(TreeNode.scala:568)
	at org.apache.spark.sql.execution.WholeStageCodegenExec.generateTreeString(WholeStageCodegenExec.scala:675)
	at org.apache.spark.sql.catalyst.trees.TreeNode.generateTreeString(TreeNode.scala:568)
	at org.apache.spark.sql.execution.InputAdapter.generateTreeString(WholeStageCodegenExec.scala:399)
	at org.apache.spark.sql.catalyst.trees.TreeNode.generateTreeString(TreeNode.scala:568)
	at org.apache.spark.sql.execution.WholeStageCodegenExec.generateTreeString(WholeStageCodegenExec.scala:675)
	at org.apache.spark.sql.catalyst.trees.TreeNode.generateTreeString(TreeNode.scala:568)
	at org.apache.spark.sql.execution.InputAdapter.generateTreeString(WholeStageCodegenExec.scala:399)
	at org.apache.spark.sql.catalyst.trees.TreeNode.generateTreeString(TreeNode.scala:568)
	at org.apache.spark.sql.execution.WholeStageCodegenExec.generateTreeString(WholeStageCodegenExec.scala:675)
	at org.apache.spark.sql.catalyst.trees.TreeNode.generateTreeString(TreeNode.scala:568)
	at org.apache.spark.sql.execution.InputAdapter.generateTreeString(WholeStageCodegenExec.scala:399)
	at org.apache.spark.sql.catalyst.trees.TreeNode.generateTreeString(TreeNode.scala:568)
	at org.apache.spark.sql.execution.WholeStageCodegenExec.generateTreeString(WholeStageCodegenExec.scala:675)
	at org.apache.spark.sql.catalyst.trees.TreeNode.generateTreeString(TreeNode.scala:568)
	at org.apache.spark.sql.catalyst.trees.TreeNode.treeString(TreeNode.scala:472)
	at org.apache.spark.sql.execution.QueryExecution$$anonfun$toString$3.apply(QueryExecution.scala:207)
	at org.apache.spark.sql.execution.QueryExecution$$anonfun$toString$3.apply(QueryExecution.scala:207)
	at org.apache.spark.sql.execution.QueryExecution.stringOrError(QueryExecution.scala:99)
	at org.apache.spark.sql.execution.QueryExecution.toString(QueryExecution.scala:207)
	at org.apache.spark.sql.execution.SQLExecution$$anonfun$withNewExecutionId$1.apply(SQLExecution.scala:75)
	at org.apache.spark.sql.execution.SQLExecution$.withSQLConfPropagated(SQLExecution.scala:125)
	at org.apache.spark.sql.execution.SQLExecution$.withNewExecutionId(SQLExecution.scala:73)
	at org.apache.spark.sql.Dataset.withAction(Dataset.scala:3364)
	at org.apache.spark.sql.Dataset.head(Dataset.scala:2545)
	at org.apache.spark.sql.Dataset.take(Dataset.scala:2759)
	at edf.missingdataload.MissingRecords$.identifyMissingRecords(MissingRecords.scala:51)
	at edf.missingdataload.FindAndLoadMissingRecords$$anonfun$6.apply(FindAndLoadMissingRecords.scala:83)
	at edf.missingdataload.FindAndLoadMissingRecords$$anonfun$6.apply(FindAndLoadMissingRecords.scala:83)
	at scala.collection.parallel.AugmentedIterableIterator$class.map2combiner(RemainsIterator.scala:115)
	at scala.collection.parallel.immutable.ParHashMap$ParHashMapIterator.map2combiner(ParHashMap.scala:76)
	at scala.collection.parallel.ParIterableLike$Map.leaf(ParIterableLike.scala:1054)
	at scala.collection.parallel.Task$$anonfun$tryLeaf$1.apply$mcV$sp(Tasks.scala:49)
	at scala.collection.parallel.Task$$anonfun$tryLeaf$1.apply(Tasks.scala:48)
	at scala.collection.parallel.Task$$anonfun$tryLeaf$1.apply(Tasks.scala:48)
	at scala.collection.parallel.Task$class.tryLeaf(Tasks.scala:51)
	at scala.collection.parallel.ParIterableLike$Map.tryLeaf(ParIterableLike.scala:1051)
	at scala.collection.parallel.AdaptiveWorkStealingTasks$WrappedTask$class.internal(Tasks.scala:159)
	at scala.collection.parallel.AdaptiveWorkStealingForkJoinTasks$WrappedTask.internal(Tasks.scala:443)
	at scala.collection.parallel.AdaptiveWorkStealingTasks$WrappedTask$class.compute(Tasks.scala:149)
	at scala.collection.parallel.AdaptiveWorkStealingForkJoinTasks$WrappedTask.compute(Tasks.scala:443)
	at scala.concurrent.forkjoin.RecursiveAction.exec(RecursiveAction.java:160)
	at scala.concurrent.forkjoin.ForkJoinTask.doExec(ForkJoinTask.java:260)
	at scala.concurrent.forkjoin.ForkJoinTask.doJoin(ForkJoinTask.java:341)
	at scala.concurrent.forkjoin.ForkJoinTask.join(ForkJoinTask.java:673)
	at scala.collection.parallel.ForkJoinTasks$WrappedTask$class.sync(Tasks.scala:378)
	at scala.collection.parallel.AdaptiveWorkStealingForkJoinTasks$WrappedTask.sync(Tasks.scala:443)
	at scala.collection.parallel.ForkJoinTasks$class.executeAndWaitResult(Tasks.scala:426)
	at scala.collection.parallel.ForkJoinTaskSupport.executeAndWaitResult(TaskSupport.scala:56)
	at scala.collection.parallel.ExecutionContextTasks$class.executeAndWaitResult(Tasks.scala:558)
	at scala.collection.parallel.ExecutionContextTaskSupport.executeAndWaitResult(TaskSupport.scala:80)
	at scala.collection.parallel.ParIterableLike$ResultMapping.leaf(ParIterableLike.scala:958)
	at scala.collection.parallel.Task$$anonfun$tryLeaf$1.apply$mcV$sp(Tasks.scala:49)
	at scala.collection.parallel.Task$$anonfun$tryLeaf$1.apply(Tasks.scala:48)
	at scala.collection.parallel.Task$$anonfun$tryLeaf$1.apply(Tasks.scala:48)
	at scala.collection.parallel.Task$class.tryLeaf(Tasks.scala:51)
	at scala.collection.parallel.ParIterableLike$ResultMapping.tryLeaf(ParIterableLike.scala:953)
	at scala.collection.parallel.AdaptiveWorkStealingTasks$WrappedTask$class.compute(Tasks.scala:152)
	at scala.collection.parallel.AdaptiveWorkStealingForkJoinTasks$WrappedTask.compute(Tasks.scala:443)
	at scala.concurrent.forkjoin.RecursiveAction.exec(RecursiveAction.java:160)
	at scala.concurrent.forkjoin.ForkJoinTask.doExec(ForkJoinTask.java:260)
	at scala.concurrent.forkjoin.ForkJoinPool$WorkQueue.runTask(ForkJoinPool.java:1339)
	at scala.concurrent.forkjoin.ForkJoinPool.runWorker(ForkJoinPool.java:1979)
	at scala.concurrent.forkjoin.ForkJoinWorkerThread.run(ForkJoinWorkerThread.java:107)
Caused by: java.io.IOException: com.amazon.ws.emr.hadoop.fs.shaded.com.amazonaws.services.s3.model.AmazonS3Exception: Slow Down (Service: Amazon S3; Status Code: 503; Error Code: 503 Slow Down; Request ID: 7224C1654622C38F; S3 Extended Request ID: kDTVvl0rvOdetv3FAhsaXCnbpHcLfIFE2D4G+hQKDKGcZ3IiM5EMGZQ5UYGiZvBSLnZ3OvjkMXY=), S3 Extended Request ID: kDTVvl0rvOdetv3FAhsaXCnbpHcLfIFE2D4G+hQKDKGcZ3IiM5EMGZQ5UYGiZvBSLnZ3OvjkMXY=
	at com.amazon.ws.emr.hadoop.fs.s3n2.S3NativeFileSystem2.listStatus(S3NativeFileSystem2.java:237)
	at com.amazon.ws.emr.hadoop.fs.EmrFileSystem.listStatus(EmrFileSystem.java:373)
	at org.apache.spark.sql.execution.datasources.InMemoryFileIndex$.org$apache$spark$sql$execution$datasources$InMemoryFileIndex$$listLeafFiles(InMemoryFileIndex.scala:277)
	at org.apache.spark.sql.execution.datasources.InMemoryFileIndex$$anonfun$3$$anonfun$apply$2.apply(InMemoryFileIndex.scala:207)
	at org.apache.spark.sql.execution.datasources.InMemoryFileIndex$$anonfun$3$$anonfun$apply$2.apply(InMemoryFileIndex.scala:206)
	at scala.collection.immutable.Stream.map(Stream.scala:418)
	at org.apache.spark.sql.execution.datasources.InMemoryFileIndex$$anonfun$3.apply(InMemoryFileIndex.scala:206)
	at org.apache.spark.sql.execution.datasources.InMemoryFileIndex$$anonfun$3.apply(InMemoryFileIndex.scala:204)
	at org.apache.spark.rdd.RDD$$anonfun$mapPartitions$1$$anonfun$apply$23.apply(RDD.scala:801)
	at org.apache.spark.rdd.RDD$$anonfun$mapPartitions$1$$anonfun$apply$23.apply(RDD.scala:801)
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:324)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:288)
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:324)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:288)
	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90)
	at org.apache.spark.scheduler.Task.run(Task.scala:121)
	at org.apache.spark.executor.Executor$TaskRunner$$anonfun$10.apply(Executor.scala:402)
	at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1360)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:408)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
Caused by: com.amazon.ws.emr.hadoop.fs.shaded.com.amazonaws.services.s3.model.AmazonS3Exception: Slow Down (Service: Amazon S3; Status Code: 503; Error Code: 503 Slow Down; Request ID: 7224C1654622C38F; S3 Extended Request ID: kDTVvl0rvOdetv3FAhsaXCnbpHcLfIFE2D4G+hQKDKGcZ3IiM5EMGZQ5UYGiZvBSLnZ3OvjkMXY=), S3 Extended Request ID: kDTVvl0rvOdetv3FAhsaXCnbpHcLfIFE2D4G+hQKDKGcZ3IiM5EMGZQ5UYGiZvBSLnZ3OvjkMXY=
	at com.amazon.ws.emr.hadoop.fs.shaded.com.amazonaws.http.AmazonHttpClient$RequestExecutor.handleErrorResponse(AmazonHttpClient.java:1658)
	at com.amazon.ws.emr.hadoop.fs.shaded.com.amazonaws.http.AmazonHttpClient$RequestExecutor.executeOneRequest(AmazonHttpClient.java:1322)
	at com.amazon.ws.emr.hadoop.fs.shaded.com.amazonaws.http.AmazonHttpClient$RequestExecutor.executeHelper(AmazonHttpClient.java:1072)
	at com.amazon.ws.emr.hadoop.fs.shaded.com.amazonaws.http.AmazonHttpClient$RequestExecutor.doExecute(AmazonHttpClient.java:745)
	at com.amazon.ws.emr.hadoop.fs.shaded.com.amazonaws.http.AmazonHttpClient$RequestExecutor.executeWithTimer(AmazonHttpClient.java:719)
	at com.amazon.ws.emr.hadoop.fs.shaded.com.amazonaws.http.AmazonHttpClient$RequestExecutor.execute(AmazonHttpClient.java:701)
	at com.amazon.ws.emr.hadoop.fs.shaded.com.amazonaws.http.AmazonHttpClient$RequestExecutor.access$500(AmazonHttpClient.java:669)
	at com.amazon.ws.emr.hadoop.fs.shaded.com.amazonaws.http.AmazonHttpClient$RequestExecutionBuilderImpl.execute(AmazonHttpClient.java:651)
	at com.amazon.ws.emr.hadoop.fs.shaded.com.amazonaws.http.AmazonHttpClient.execute(AmazonHttpClient.java:515)
	at com.amazon.ws.emr.hadoop.fs.shaded.com.amazonaws.services.s3.AmazonS3Client.invoke(AmazonS3Client.java:4443)
	at com.amazon.ws.emr.hadoop.fs.shaded.com.amazonaws.services.s3.AmazonS3Client.invoke(AmazonS3Client.java:4390)
	at com.amazon.ws.emr.hadoop.fs.shaded.com.amazonaws.services.s3.AmazonS3Client.getObjectMetadata(AmazonS3Client.java:1280)
	at com.amazon.ws.emr.hadoop.fs.s3.lite.call.GetObjectMetadataCall.perform(GetObjectMetadataCall.java:22)
	at com.amazon.ws.emr.hadoop.fs.s3.lite.call.GetObjectMetadataCall.perform(GetObjectMetadataCall.java:8)
	at com.amazon.ws.emr.hadoop.fs.s3.lite.executor.GlobalS3Executor.execute(GlobalS3Executor.java:91)
	at com.amazon.ws.emr.hadoop.fs.s3.lite.AmazonS3LiteClient.invoke(AmazonS3LiteClient.java:184)
	at com.amazon.ws.emr.hadoop.fs.s3.lite.AmazonS3LiteClient.getObjectMetadata(AmazonS3LiteClient.java:96)
	at com.amazon.ws.emr.hadoop.fs.consistency.ConsistencyCheckerS3FileSystem.getObjectMetadata(ConsistencyCheckerS3FileSystem.java:973)
	at com.amazon.ws.emr.hadoop.fs.consistency.ConsistencyCheckerS3FileSystem.getFileStatusFromS3CheckingConsistencyIfEnabled(ConsistencyCheckerS3FileSystem.java:439)
	at com.amazon.ws.emr.hadoop.fs.consistency.ConsistencyCheckerS3FileSystem.getFileStatus(ConsistencyCheckerS3FileSystem.java:406)
	at com.amazon.ws.emr.hadoop.fs.consistency.ConsistencyCheckerS3FileSystem.getFileStatus(ConsistencyCheckerS3FileSystem.java:399)
	at com.amazon.ws.emr.hadoop.fs.consistency.ConsistencyCheckerS3FileSystem.listStatus(ConsistencyCheckerS3FileSystem.java:510)
	at sun.reflect.GeneratedMethodAccessor58.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:409)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invokeMethod(RetryInvocationHandler.java:163)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invoke(RetryInvocationHandler.java:155)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invokeOnce(RetryInvocationHandler.java:95)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:346)
	at com.sun.proxy.$Proxy37.listStatus(Unknown Source)
	at com.amazon.ws.emr.hadoop.fs.s3n2.S3NativeFileSystem2.listStatus(S3NativeFileSystem2.java:224)
	... 23 more

	 ApplicationMaster host: ip-10-84-36-42.corp.stateauto.com
	 ApplicationMaster RPC port: 43247
	 queue: default
	 start time: 1582821683950
	 final status: FAILED
	 tracking URL: http://ip-10-84-38-68.corp.stateauto.com:20888/proxy/application_1578014764864_32354/
	 user: hadoop
20/02/27 16:46:44 ERROR Client: Application diagnostics message: User class threw exception: org.apache.spark.SparkException: Job aborted due to stage failure: Task 99 in stage 110.0 failed 4 times, most recent failure: Lost task 99.3 in stage 110.0 (TID 13297, ip-10-84-46-117.corp.stateauto.com, executor 26): java.io.IOException: com.amazon.ws.emr.hadoop.fs.shaded.com.amazonaws.services.s3.model.AmazonS3Exception: Slow Down (Service: Amazon S3; Status Code: 503; Error Code: 503 Slow Down; Request ID: 7224C1654622C38F; S3 Extended Request ID: kDTVvl0rvOdetv3FAhsaXCnbpHcLfIFE2D4G+hQKDKGcZ3IiM5EMGZQ5UYGiZvBSLnZ3OvjkMXY=), S3 Extended Request ID: kDTVvl0rvOdetv3FAhsaXCnbpHcLfIFE2D4G+hQKDKGcZ3IiM5EMGZQ5UYGiZvBSLnZ3OvjkMXY=
	at com.amazon.ws.emr.hadoop.fs.s3n2.S3NativeFileSystem2.listStatus(S3NativeFileSystem2.java:237)
	at com.amazon.ws.emr.hadoop.fs.EmrFileSystem.listStatus(EmrFileSystem.java:373)
	at org.apache.spark.sql.execution.datasources.InMemoryFileIndex$.org$apache$spark$sql$execution$datasources$InMemoryFileIndex$$listLeafFiles(InMemoryFileIndex.scala:277)
	at org.apache.spark.sql.execution.datasources.InMemoryFileIndex$$anonfun$3$$anonfun$apply$2.apply(InMemoryFileIndex.scala:207)
	at org.apache.spark.sql.execution.datasources.InMemoryFileIndex$$anonfun$3$$anonfun$apply$2.apply(InMemoryFileIndex.scala:206)
	at scala.collection.immutable.Stream.map(Stream.scala:418)
	at org.apache.spark.sql.execution.datasources.InMemoryFileIndex$$anonfun$3.apply(InMemoryFileIndex.scala:206)
	at org.apache.spark.sql.execution.datasources.InMemoryFileIndex$$anonfun$3.apply(InMemoryFileIndex.scala:204)
	at org.apache.spark.rdd.RDD$$anonfun$mapPartitions$1$$anonfun$apply$23.apply(RDD.scala:801)
	at org.apache.spark.rdd.RDD$$anonfun$mapPartitions$1$$anonfun$apply$23.apply(RDD.scala:801)
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:324)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:288)
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:324)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:288)
	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90)
	at org.apache.spark.scheduler.Task.run(Task.scala:121)
	at org.apache.spark.executor.Executor$TaskRunner$$anonfun$10.apply(Executor.scala:402)
	at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1360)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:408)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
Caused by: com.amazon.ws.emr.hadoop.fs.shaded.com.amazonaws.services.s3.model.AmazonS3Exception: Slow Down (Service: Amazon S3; Status Code: 503; Error Code: 503 Slow Down; Request ID: 7224C1654622C38F; S3 Extended Request ID: kDTVvl0rvOdetv3FAhsaXCnbpHcLfIFE2D4G+hQKDKGcZ3IiM5EMGZQ5UYGiZvBSLnZ3OvjkMXY=), S3 Extended Request ID: kDTVvl0rvOdetv3FAhsaXCnbpHcLfIFE2D4G+hQKDKGcZ3IiM5EMGZQ5UYGiZvBSLnZ3OvjkMXY=
	at com.amazon.ws.emr.hadoop.fs.shaded.com.amazonaws.http.AmazonHttpClient$RequestExecutor.handleErrorResponse(AmazonHttpClient.java:1658)
	at com.amazon.ws.emr.hadoop.fs.shaded.com.amazonaws.http.AmazonHttpClient$RequestExecutor.executeOneRequest(AmazonHttpClient.java:1322)
	at com.amazon.ws.emr.hadoop.fs.shaded.com.amazonaws.http.AmazonHttpClient$RequestExecutor.executeHelper(AmazonHttpClient.java:1072)
	at com.amazon.ws.emr.hadoop.fs.shaded.com.amazonaws.http.AmazonHttpClient$RequestExecutor.doExecute(AmazonHttpClient.java:745)
	at com.amazon.ws.emr.hadoop.fs.shaded.com.amazonaws.http.AmazonHttpClient$RequestExecutor.executeWithTimer(AmazonHttpClient.java:719)
	at com.amazon.ws.emr.hadoop.fs.shaded.com.amazonaws.http.AmazonHttpClient$RequestExecutor.execute(AmazonHttpClient.java:701)
	at com.amazon.ws.emr.hadoop.fs.shaded.com.amazonaws.http.AmazonHttpClient$RequestExecutor.access$500(AmazonHttpClient.java:669)
	at com.amazon.ws.emr.hadoop.fs.shaded.com.amazonaws.http.AmazonHttpClient$RequestExecutionBuilderImpl.execute(AmazonHttpClient.java:651)
	at com.amazon.ws.emr.hadoop.fs.shaded.com.amazonaws.http.AmazonHttpClient.execute(AmazonHttpClient.java:515)
	at com.amazon.ws.emr.hadoop.fs.shaded.com.amazonaws.services.s3.AmazonS3Client.invoke(AmazonS3Client.java:4443)
	at com.amazon.ws.emr.hadoop.fs.shaded.com.amazonaws.services.s3.AmazonS3Client.invoke(AmazonS3Client.java:4390)
	at com.amazon.ws.emr.hadoop.fs.shaded.com.amazonaws.services.s3.AmazonS3Client.getObjectMetadata(AmazonS3Client.java:1280)
	at com.amazon.ws.emr.hadoop.fs.s3.lite.call.GetObjectMetadataCall.perform(GetObjectMetadataCall.java:22)
	at com.amazon.ws.emr.hadoop.fs.s3.lite.call.GetObjectMetadataCall.perform(GetObjectMetadataCall.java:8)
	at com.amazon.ws.emr.hadoop.fs.s3.lite.executor.GlobalS3Executor.execute(GlobalS3Executor.java:91)
	at com.amazon.ws.emr.hadoop.fs.s3.lite.AmazonS3LiteClient.invoke(AmazonS3LiteClient.java:184)
	at com.amazon.ws.emr.hadoop.fs.s3.lite.AmazonS3LiteClient.getObjectMetadata(AmazonS3LiteClient.java:96)
	at com.amazon.ws.emr.hadoop.fs.consistency.ConsistencyCheckerS3FileSystem.getObjectMetadata(ConsistencyCheckerS3FileSystem.java:973)
	at com.amazon.ws.emr.hadoop.fs.consistency.ConsistencyCheckerS3FileSystem.getFileStatusFromS3CheckingConsistencyIfEnabled(ConsistencyCheckerS3FileSystem.java:439)
	at com.amazon.ws.emr.hadoop.fs.consistency.ConsistencyCheckerS3FileSystem.getFileStatus(ConsistencyCheckerS3FileSystem.java:406)
	at com.amazon.ws.emr.hadoop.fs.consistency.ConsistencyCheckerS3FileSystem.getFileStatus(ConsistencyCheckerS3FileSystem.java:399)
	at com.amazon.ws.emr.hadoop.fs.consistency.ConsistencyCheckerS3FileSystem.listStatus(ConsistencyCheckerS3FileSystem.java:510)
	at sun.reflect.GeneratedMethodAccessor58.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:409)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invokeMethod(RetryInvocationHandler.java:163)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invoke(RetryInvocationHandler.java:155)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invokeOnce(RetryInvocationHandler.java:95)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:346)
	at com.sun.proxy.$Proxy37.listStatus(Unknown Source)
	at com.amazon.ws.emr.hadoop.fs.s3n2.S3NativeFileSystem2.listStatus(S3NativeFileSystem2.java:224)
	... 23 more

Driver stacktrace:
	at org.apache.spark.scheduler.DAGScheduler.org$apache$spark$scheduler$DAGScheduler$$failJobAndIndependentStages(DAGScheduler.scala:2039)
	at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:2027)
	at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:2026)
	at scala.collection.mutable.ResizableArray$class.foreach(ResizableArray.scala:59)
	at scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:48)
	at org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:2026)
	at org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:966)
	at org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:966)
	at scala.Option.foreach(Option.scala:257)
	at org.apache.spark.scheduler.DAGScheduler.handleTaskSetFailed(DAGScheduler.scala:966)
	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.doOnReceive(DAGScheduler.scala:2260)
	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:2209)
	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:2198)
	at org.apache.spark.util.EventLoop$$anon$1.run(EventLoop.scala:49)
	at org.apache.spark.scheduler.DAGScheduler.runJob(DAGScheduler.scala:777)
	at org.apache.spark.SparkContext.runJob(SparkContext.scala:2061)
	at org.apache.spark.SparkContext.runJob(SparkContext.scala:2082)
	at org.apache.spark.SparkContext.runJob(SparkContext.scala:2101)
	at org.apache.spark.SparkContext.runJob(SparkContext.scala:2126)
	at org.apache.spark.rdd.RDD$$anonfun$collect$1.apply(RDD.scala:945)
	at org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:151)
	at org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:112)
	at org.apache.spark.rdd.RDD.withScope(RDD.scala:363)
	at org.apache.spark.rdd.RDD.collect(RDD.scala:944)
	at org.apache.spark.sql.execution.datasources.InMemoryFileIndex$.bulkListLeafFiles(InMemoryFileIndex.scala:237)
	at org.apache.spark.sql.execution.datasources.InMemoryFileIndex.listLeafFiles(InMemoryFileIndex.scala:126)
	at org.apache.spark.sql.execution.datasources.InMemoryFileIndex.refresh0(InMemoryFileIndex.scala:91)
	at org.apache.spark.sql.execution.datasources.InMemoryFileIndex.<init>(InMemoryFileIndex.scala:67)
	at org.apache.spark.sql.execution.datasources.PrunedInMemoryFileIndex.<init>(CatalogFileIndex.scala:118)
	at org.apache.spark.sql.execution.datasources.CatalogFileIndex.filterPartitions(CatalogFileIndex.scala:84)
	at org.apache.spark.sql.execution.datasources.CatalogFileIndex.listFiles(CatalogFileIndex.scala:59)
	at org.apache.spark.sql.execution.FileSourceScanExec.org$apache$spark$sql$execution$FileSourceScanExec$$selectedPartitions$lzycompute(DataSourceScanExec.scala:191)
	at org.apache.spark.sql.execution.FileSourceScanExec.org$apache$spark$sql$execution$FileSourceScanExec$$selectedPartitions(DataSourceScanExec.scala:188)
	at org.apache.spark.sql.execution.FileSourceScanExec$$anonfun$22.apply(DataSourceScanExec.scala:290)
	at org.apache.spark.sql.execution.FileSourceScanExec$$anonfun$22.apply(DataSourceScanExec.scala:289)
	at scala.Option.map(Option.scala:146)
	at org.apache.spark.sql.execution.FileSourceScanExec.metadata$lzycompute(DataSourceScanExec.scala:289)
	at org.apache.spark.sql.execution.FileSourceScanExec.metadata(DataSourceScanExec.scala:275)
	at org.apache.spark.sql.execution.DataSourceScanExec$class.simpleString(DataSourceScanExec.scala:55)
	at org.apache.spark.sql.execution.FileSourceScanExec.simpleString(DataSourceScanExec.scala:159)
	at org.apache.spark.sql.catalyst.plans.QueryPlan.verboseString(QueryPlan.scala:177)
	at org.apache.spark.sql.execution.FileSourceScanExec.org$apache$spark$sql$execution$DataSourceScanExec$$super$verboseString(DataSourceScanExec.scala:159)
	at org.apache.spark.sql.execution.DataSourceScanExec$class.verboseString(DataSourceScanExec.scala:63)
	at org.apache.spark.sql.execution.FileSourceScanExec.verboseString(DataSourceScanExec.scala:159)
	at org.apache.spark.sql.catalyst.trees.TreeNode.generateTreeString(TreeNode.scala:548)
	at org.apache.spark.sql.catalyst.trees.TreeNode.generateTreeString(TreeNode.scala:568)
	at org.apache.spark.sql.execution.WholeStageCodegenExec.generateTreeString(WholeStageCodegenExec.scala:675)
	at org.apache.spark.sql.catalyst.trees.TreeNode.generateTreeString(TreeNode.scala:568)
	at org.apache.spark.sql.execution.InputAdapter.generateTreeString(WholeStageCodegenExec.scala:399)
	at org.apache.spark.sql.catalyst.trees.TreeNode.generateTreeString(TreeNode.scala:568)
	at org.apache.spark.sql.execution.WholeStageCodegenExec.generateTreeString(WholeStageCodegenExec.scala:675)
	at org.apache.spark.sql.catalyst.trees.TreeNode.generateTreeString(TreeNode.scala:568)
	at org.apache.spark.sql.execution.InputAdapter.generateTreeString(WholeStageCodegenExec.scala:399)
	at org.apache.spark.sql.catalyst.trees.TreeNode.generateTreeString(TreeNode.scala:568)
	at org.apache.spark.sql.execution.WholeStageCodegenExec.generateTreeString(WholeStageCodegenExec.scala:675)
	at org.apache.spark.sql.catalyst.trees.TreeNode.generateTreeString(TreeNode.scala:568)
	at org.apache.spark.sql.execution.InputAdapter.generateTreeString(WholeStageCodegenExec.scala:399)
	at org.apache.spark.sql.catalyst.trees.TreeNode.generateTreeString(TreeNode.scala:568)
	at org.apache.spark.sql.execution.WholeStageCodegenExec.generateTreeString(WholeStageCodegenExec.scala:675)
	at org.apache.spark.sql.catalyst.trees.TreeNode.generateTreeString(TreeNode.scala:568)
	at org.apache.spark.sql.catalyst.trees.TreeNode.treeString(TreeNode.scala:472)
	at org.apache.spark.sql.execution.QueryExecution$$anonfun$toString$3.apply(QueryExecution.scala:207)
	at org.apache.spark.sql.execution.QueryExecution$$anonfun$toString$3.apply(QueryExecution.scala:207)
	at org.apache.spark.sql.execution.QueryExecution.stringOrError(QueryExecution.scala:99)
	at org.apache.spark.sql.execution.QueryExecution.toString(QueryExecution.scala:207)
	at org.apache.spark.sql.execution.SQLExecution$$anonfun$withNewExecutionId$1.apply(SQLExecution.scala:75)
	at org.apache.spark.sql.execution.SQLExecution$.withSQLConfPropagated(SQLExecution.scala:125)
	at org.apache.spark.sql.execution.SQLExecution$.withNewExecutionId(SQLExecution.scala:73)
	at org.apache.spark.sql.Dataset.withAction(Dataset.scala:3364)
	at org.apache.spark.sql.Dataset.head(Dataset.scala:2545)
	at org.apache.spark.sql.Dataset.take(Dataset.scala:2759)
	at edf.missingdataload.MissingRecords$.identifyMissingRecords(MissingRecords.scala:51)
	at edf.missingdataload.FindAndLoadMissingRecords$$anonfun$6.apply(FindAndLoadMissingRecords.scala:83)
	at edf.missingdataload.FindAndLoadMissingRecords$$anonfun$6.apply(FindAndLoadMissingRecords.scala:83)
	at scala.collection.parallel.AugmentedIterableIterator$class.map2combiner(RemainsIterator.scala:115)
	at scala.collection.parallel.immutable.ParHashMap$ParHashMapIterator.map2combiner(ParHashMap.scala:76)
	at scala.collection.parallel.ParIterableLike$Map.leaf(ParIterableLike.scala:1054)
	at scala.collection.parallel.Task$$anonfun$tryLeaf$1.apply$mcV$sp(Tasks.scala:49)
	at scala.collection.parallel.Task$$anonfun$tryLeaf$1.apply(Tasks.scala:48)
	at scala.collection.parallel.Task$$anonfun$tryLeaf$1.apply(Tasks.scala:48)
	at scala.collection.parallel.Task$class.tryLeaf(Tasks.scala:51)
	at scala.collection.parallel.ParIterableLike$Map.tryLeaf(ParIterableLike.scala:1051)
	at scala.collection.parallel.AdaptiveWorkStealingTasks$WrappedTask$class.internal(Tasks.scala:159)
	at scala.collection.parallel.AdaptiveWorkStealingForkJoinTasks$WrappedTask.internal(Tasks.scala:443)
	at scala.collection.parallel.AdaptiveWorkStealingTasks$WrappedTask$class.compute(Tasks.scala:149)
	at scala.collection.parallel.AdaptiveWorkStealingForkJoinTasks$WrappedTask.compute(Tasks.scala:443)
	at scala.concurrent.forkjoin.RecursiveAction.exec(RecursiveAction.java:160)
	at scala.concurrent.forkjoin.ForkJoinTask.doExec(ForkJoinTask.java:260)
	at scala.concurrent.forkjoin.ForkJoinTask.doJoin(ForkJoinTask.java:341)
	at scala.concurrent.forkjoin.ForkJoinTask.join(ForkJoinTask.java:673)
	at scala.collection.parallel.ForkJoinTasks$WrappedTask$class.sync(Tasks.scala:378)
	at scala.collection.parallel.AdaptiveWorkStealingForkJoinTasks$WrappedTask.sync(Tasks.scala:443)
	at scala.collection.parallel.ForkJoinTasks$class.executeAndWaitResult(Tasks.scala:426)
	at scala.collection.parallel.ForkJoinTaskSupport.executeAndWaitResult(TaskSupport.scala:56)
	at scala.collection.parallel.ExecutionContextTasks$class.executeAndWaitResult(Tasks.scala:558)
	at scala.collection.parallel.ExecutionContextTaskSupport.executeAndWaitResult(TaskSupport.scala:80)
	at scala.collection.parallel.ParIterableLike$ResultMapping.leaf(ParIterableLike.scala:958)
	at scala.collection.parallel.Task$$anonfun$tryLeaf$1.apply$mcV$sp(Tasks.scala:49)
	at scala.collection.parallel.Task$$anonfun$tryLeaf$1.apply(Tasks.scala:48)
	at scala.collection.parallel.Task$$anonfun$tryLeaf$1.apply(Tasks.scala:48)
	at scala.collection.parallel.Task$class.tryLeaf(Tasks.scala:51)
	at scala.collection.parallel.ParIterableLike$ResultMapping.tryLeaf(ParIterableLike.scala:953)
	at scala.collection.parallel.AdaptiveWorkStealingTasks$WrappedTask$class.compute(Tasks.scala:152)
	at scala.collection.parallel.AdaptiveWorkStealingForkJoinTasks$WrappedTask.compute(Tasks.scala:443)
	at scala.concurrent.forkjoin.RecursiveAction.exec(RecursiveAction.java:160)
	at scala.concurrent.forkjoin.ForkJoinTask.doExec(ForkJoinTask.java:260)
	at scala.concurrent.forkjoin.ForkJoinPool$WorkQueue.runTask(ForkJoinPool.java:1339)
	at scala.concurrent.forkjoin.ForkJoinPool.runWorker(ForkJoinPool.java:1979)
	at scala.concurrent.forkjoin.ForkJoinWorkerThread.run(ForkJoinWorkerThread.java:107)
Caused by: java.io.IOException: com.amazon.ws.emr.hadoop.fs.shaded.com.amazonaws.services.s3.model.AmazonS3Exception: Slow Down (Service: Amazon S3; Status Code: 503; Error Code: 503 Slow Down; Request ID: 7224C1654622C38F; S3 Extended Request ID: kDTVvl0rvOdetv3FAhsaXCnbpHcLfIFE2D4G+hQKDKGcZ3IiM5EMGZQ5UYGiZvBSLnZ3OvjkMXY=), S3 Extended Request ID: kDTVvl0rvOdetv3FAhsaXCnbpHcLfIFE2D4G+hQKDKGcZ3IiM5EMGZQ5UYGiZvBSLnZ3OvjkMXY=
	at com.amazon.ws.emr.hadoop.fs.s3n2.S3NativeFileSystem2.listStatus(S3NativeFileSystem2.java:237)
	at com.amazon.ws.emr.hadoop.fs.EmrFileSystem.listStatus(EmrFileSystem.java:373)
	at org.apache.spark.sql.execution.datasources.InMemoryFileIndex$.org$apache$spark$sql$execution$datasources$InMemoryFileIndex$$listLeafFiles(InMemoryFileIndex.scala:277)
	at org.apache.spark.sql.execution.datasources.InMemoryFileIndex$$anonfun$3$$anonfun$apply$2.apply(InMemoryFileIndex.scala:207)
	at org.apache.spark.sql.execution.datasources.InMemoryFileIndex$$anonfun$3$$anonfun$apply$2.apply(InMemoryFileIndex.scala:206)
	at scala.collection.immutable.Stream.map(Stream.scala:418)
	at org.apache.spark.sql.execution.datasources.InMemoryFileIndex$$anonfun$3.apply(InMemoryFileIndex.scala:206)
	at org.apache.spark.sql.execution.datasources.InMemoryFileIndex$$anonfun$3.apply(InMemoryFileIndex.scala:204)
	at org.apache.spark.rdd.RDD$$anonfun$mapPartitions$1$$anonfun$apply$23.apply(RDD.scala:801)
	at org.apache.spark.rdd.RDD$$anonfun$mapPartitions$1$$anonfun$apply$23.apply(RDD.scala:801)
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:324)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:288)
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:324)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:288)
	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90)
	at org.apache.spark.scheduler.Task.run(Task.scala:121)
	at org.apache.spark.executor.Executor$TaskRunner$$anonfun$10.apply(Executor.scala:402)
	at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1360)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:408)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
Caused by: com.amazon.ws.emr.hadoop.fs.shaded.com.amazonaws.services.s3.model.AmazonS3Exception: Slow Down (Service: Amazon S3; Status Code: 503; Error Code: 503 Slow Down; Request ID: 7224C1654622C38F; S3 Extended Request ID: kDTVvl0rvOdetv3FAhsaXCnbpHcLfIFE2D4G+hQKDKGcZ3IiM5EMGZQ5UYGiZvBSLnZ3OvjkMXY=), S3 Extended Request ID: kDTVvl0rvOdetv3FAhsaXCnbpHcLfIFE2D4G+hQKDKGcZ3IiM5EMGZQ5UYGiZvBSLnZ3OvjkMXY=
	at com.amazon.ws.emr.hadoop.fs.shaded.com.amazonaws.http.AmazonHttpClient$RequestExecutor.handleErrorResponse(AmazonHttpClient.java:1658)
	at com.amazon.ws.emr.hadoop.fs.shaded.com.amazonaws.http.AmazonHttpClient$RequestExecutor.executeOneRequest(AmazonHttpClient.java:1322)
	at com.amazon.ws.emr.hadoop.fs.shaded.com.amazonaws.http.AmazonHttpClient$RequestExecutor.executeHelper(AmazonHttpClient.java:1072)
	at com.amazon.ws.emr.hadoop.fs.shaded.com.amazonaws.http.AmazonHttpClient$RequestExecutor.doExecute(AmazonHttpClient.java:745)
	at com.amazon.ws.emr.hadoop.fs.shaded.com.amazonaws.http.AmazonHttpClient$RequestExecutor.executeWithTimer(AmazonHttpClient.java:719)
	at com.amazon.ws.emr.hadoop.fs.shaded.com.amazonaws.http.AmazonHttpClient$RequestExecutor.execute(AmazonHttpClient.java:701)
	at com.amazon.ws.emr.hadoop.fs.shaded.com.amazonaws.http.AmazonHttpClient$RequestExecutor.access$500(AmazonHttpClient.java:669)
	at com.amazon.ws.emr.hadoop.fs.shaded.com.amazonaws.http.AmazonHttpClient$RequestExecutionBuilderImpl.execute(AmazonHttpClient.java:651)
	at com.amazon.ws.emr.hadoop.fs.shaded.com.amazonaws.http.AmazonHttpClient.execute(AmazonHttpClient.java:515)
	at com.amazon.ws.emr.hadoop.fs.shaded.com.amazonaws.services.s3.AmazonS3Client.invoke(AmazonS3Client.java:4443)
	at com.amazon.ws.emr.hadoop.fs.shaded.com.amazonaws.services.s3.AmazonS3Client.invoke(AmazonS3Client.java:4390)
	at com.amazon.ws.emr.hadoop.fs.shaded.com.amazonaws.services.s3.AmazonS3Client.getObjectMetadata(AmazonS3Client.java:1280)
	at com.amazon.ws.emr.hadoop.fs.s3.lite.call.GetObjectMetadataCall.perform(GetObjectMetadataCall.java:22)
	at com.amazon.ws.emr.hadoop.fs.s3.lite.call.GetObjectMetadataCall.perform(GetObjectMetadataCall.java:8)
	at com.amazon.ws.emr.hadoop.fs.s3.lite.executor.GlobalS3Executor.execute(GlobalS3Executor.java:91)
	at com.amazon.ws.emr.hadoop.fs.s3.lite.AmazonS3LiteClient.invoke(AmazonS3LiteClient.java:184)
	at com.amazon.ws.emr.hadoop.fs.s3.lite.AmazonS3LiteClient.getObjectMetadata(AmazonS3LiteClient.java:96)
	at com.amazon.ws.emr.hadoop.fs.consistency.ConsistencyCheckerS3FileSystem.getObjectMetadata(ConsistencyCheckerS3FileSystem.java:973)
	at com.amazon.ws.emr.hadoop.fs.consistency.ConsistencyCheckerS3FileSystem.getFileStatusFromS3CheckingConsistencyIfEnabled(ConsistencyCheckerS3FileSystem.java:439)
	at com.amazon.ws.emr.hadoop.fs.consistency.ConsistencyCheckerS3FileSystem.getFileStatus(ConsistencyCheckerS3FileSystem.java:406)
	at com.amazon.ws.emr.hadoop.fs.consistency.ConsistencyCheckerS3FileSystem.getFileStatus(ConsistencyCheckerS3FileSystem.java:399)
	at com.amazon.ws.emr.hadoop.fs.consistency.ConsistencyCheckerS3FileSystem.listStatus(ConsistencyCheckerS3FileSystem.java:510)
	at sun.reflect.GeneratedMethodAccessor58.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:409)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invokeMethod(RetryInvocationHandler.java:163)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invoke(RetryInvocationHandler.java:155)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invokeOnce(RetryInvocationHandler.java:95)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:346)
	at com.sun.proxy.$Proxy37.listStatus(Unknown Source)
	at com.amazon.ws.emr.hadoop.fs.s3n2.S3NativeFileSystem2.listStatus(S3NativeFileSystem2.java:224)
	... 23 more

Exception in thread "main" org.apache.spark.SparkException: Application application_1578014764864_32354 finished with failed status
	at org.apache.spark.deploy.yarn.Client.run(Client.scala:1149)
	at org.apache.spark.deploy.yarn.YarnClusterApplication.start(Client.scala:1526)
	at org.apache.spark.deploy.SparkSubmit.org$apache$spark$deploy$SparkSubmit$$runMain(SparkSubmit.scala:849)
	at org.apache.spark.deploy.SparkSubmit.doRunMain$1(SparkSubmit.scala:167)
	at org.apache.spark.deploy.SparkSubmit.submit(SparkSubmit.scala:195)
	at org.apache.spark.deploy.SparkSubmit.doSubmit(SparkSubmit.scala:86)
	at org.apache.spark.deploy.SparkSubmit$$anon$2.doSubmit(SparkSubmit.scala:924)
	at org.apache.spark.deploy.SparkSubmit$.main(SparkSubmit.scala:933)
	at org.apache.spark.deploy.SparkSubmit.main(SparkSubmit.scala)
20/02/27 16:46:44 INFO ShutdownHookManager: Shutdown hook called
20/02/27 16:46:44 INFO ShutdownHookManager: Deleting directory /mnt/tmp/spark-3229c4ba-a33f-4d38-8c2b-49fb53f47805
20/02/27 16:46:44 INFO ShutdownHookManager: Deleting directory /mnt/tmp/spark-75461bc8-4a97-4573-b57e-d2185456e0cd
