### Common parameters in all ingestion and staging load jobs ###

### Common ingestion and staging directories ###
ingestion_base_dir=/home/hadoop/uatrun/processed
ingestion_hdfs_dir=/user/hadoop/uatrun/processed
staging_base_dir=/home/hadoop/uatrun/staging
staging_hdfs_dir=/user/hadoop/uatrun/staging

### Ingestion and staging jars ###
ingestion_jar_path=/home/hadoop/uatrun/processed/jars
staging_jar_path=/home/hadoop/staging/jars
serving_jar_path=/home/hadoop/serving/jars
ingestion_jar_name=datalake_processed-assembly-2.0.0.jar
ingestion_gwcl_jar_name=datalake_processed-assembly-2.0.1.jar
#staging_jar_name=edf_staging-assembly-2.0.0.jar
staging_jar_name=datalake_staging-assembly-2.0.0.jar
staging_incr_jar_name=datalake_processed-assembly-2.1.0.jar
v6_v7_ingestion_jar_name=edf_dataingestion_v6_v7-assembly-2.0.0.jar
gain_ingestion_jar_name=edf_dataingestion_gain-assembly-2.0.0.jar
telematics_ingestion_jar_name=edf_dataingestion_telematics-assembly-2.0.0.jar
legacy_ingestion_jar_name=edf_dataingestion_legacy-assembly-2.0.0.jar
dedup_jar_name=IngstnDuplicateRmv-assembly-1.0.4.jar
#serving_jar_name=edfServing-assembly-1.0.2.jar
serving_jar_name=datalake_serving-assembly-2.0.1.jar
missingid_jar_name=edf_missing_dataingestion-assembly-2.0.0.jar

### Common Spark configuration parameters ###
spark_common_conf="spark.shuffle.spill=true --conf spark.yarn.maxAppAttempts=1 --conf spark.executor.extraJavaOptions=-XX:MaxPermSize=1024m --conf spark.sql.planner.externalSort=true --conf spark.shuffle.manager=sort  --conf spark.ui.port=8088 --conf spark.rpc.message.maxSize=1024 --conf spark.file.transferTo=false --conf spark.driver.maxResultSize=4g --conf spark.rdd.compress=true --conf spark.executor.extraJavaOptions="-Dconfig.resource=spark-defaults.conf" --conf spark.sql.broadcastTimeout=30000000 --conf spark.sql.autoBroadcastJoinThreshold=-1 --conf spark.driver.JavaOptions="-Dspark.yarn.app.container.log.dir=/mnt/var/log/hadoop" --conf spark.driver.extraJavaOptions="-Dconfig.file=spark-defaults.conf" --conf spark.sql.parquet.writeLegacyFormat=true --conf spark.enable.dynamicAllocation=true --conf spark.serializer=org.apache.spark.serializer.KryoSerializer --conf spark.kryoserializer.buffer.max=1024 --conf spark.network.timeout=360s --conf spark.executor.heartbeatInterval=60s"